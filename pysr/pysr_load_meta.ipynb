{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e649e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle, time, os, random\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.loader import DataLoader\n",
    "# accelerate huggingface to GPU\n",
    "if torch.cuda.is_available():\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "from pysr import pysr, best\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "print('Loading data')\n",
    "\n",
    "case='vlarge_all_4t_z0.0_quantile_raw'\n",
    "\n",
    "datat=pickle.load(open(osp.expanduser(f'~/../../../scratch/gpfs/cj1223/GraphStorage/{case}/data.pkl'), 'rb'))\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "data=[]\n",
    "for d in datat:\n",
    "    data.append(Data(x=d.x, edge_index=d.edge_index, edge_attr=d.edge_attr, y=d.y[0]))\n",
    "\n",
    "try:\n",
    "    n_targ=len(data[0].y)\n",
    "except:\n",
    "    n_targ=1\n",
    "n_feat=len(data[0].x[0])\n",
    "n_feat, n_targ\n",
    "\n",
    "print('Loaded data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "461c14fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelU conv activation\n",
      "LeakyRelU decode activation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = osp.expanduser('~/../../scratch/gpfs/cj1223/GraphResults')\n",
    "group = 'results_meta_pysr_120322'\n",
    "run = 'MetaEdge_vlarge_all_4t_z0.0_quantile_raw_hfpmye'\n",
    "\n",
    "model_path= osp.join(model_folder, group, run)\n",
    "construct = pickle.load(open(osp.join(model_path, 'construct_dict.pkl'), 'rb'))\n",
    "results = pickle.load(open(osp.join(model_path, 'result_dict.pkl'), 'rb'))\n",
    "\n",
    "\n",
    "model = construct['model']\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "def setup_model(model_name, hyper_params):\n",
    "    # Retrieve name and params for construction\n",
    "\n",
    "    # Load model from model folder\n",
    "    import dev.models as models\n",
    "    model         = getattr(models, model_name) \n",
    "    model         = model(**hyper_params)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = setup_model(model, construct['hyper_params'])\n",
    "\n",
    "os.chdir('pysr')\n",
    "\n",
    "model.load_state_dict(torch.load(osp.join(model_path, 'trained_model', 'model_best.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030cb3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size=int(2**8) # 8-256\n",
    "split=0.8\n",
    "test_data=data[int(len(data)*split):]\n",
    "train_data=data[:int(len(data)*split)]\n",
    "# train_data, test_data=train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=1, num_workers=4)\n",
    "\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=0, num_workers=4)    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "print('GPU ', next(model.parameters()).is_cuda)\n",
    "# Initialize our train function\n",
    "def test(loader): ##### transform back missing\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    ys = []\n",
    "    varss = []\n",
    "    with torch.no_grad(): ##this solves it!!!\n",
    "        for dat in tqdm(loader, total=len(loader)): \n",
    "            \n",
    "            out, var = model(dat) \n",
    "            ys.append(dat.y.view(-1,n_targ))\n",
    "            outs.append(out)\n",
    "            varss.append(var)\n",
    "            \n",
    "    outss=torch.vstack(outs)\n",
    "    varss=torch.vstack(outs)\n",
    "    \n",
    "    yss=torch.vstack(ys)\n",
    "    return torch.std(outss - yss, axis=0), outss, yss, varss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb2da6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': [array([0.09376801, 0.03378351, 0.19444557, 0.35171744], dtype=float32)],\n",
       " 'test_acc': [array([0.093647  , 0.03364303, 0.19445114, 0.35135224], dtype=float32),\n",
       "  array([0.9135612, 0.0970052, 0.5353335, 0.9843488], dtype=float32),\n",
       "  array([0.5910132 , 0.08898401, 0.5353486 , 0.6369817 ], dtype=float32),\n",
       "  array([0.5258665 , 0.08005344, 0.5352915 , 0.5690871 ], dtype=float32),\n",
       "  array([0.39285287, 0.07404925, 0.5352662 , 0.5401576 ], dtype=float32),\n",
       "  array([0.26816955, 0.07428045, 0.53522474, 0.5262955 ], dtype=float32),\n",
       "  array([0.25077948, 0.07039093, 0.53521633, 0.50957423], dtype=float32),\n",
       "  array([0.2560273 , 0.06913187, 0.5351986 , 0.5122538 ], dtype=float32),\n",
       "  array([0.23713616, 0.0696125 , 0.5351341 , 0.50416416], dtype=float32),\n",
       "  array([0.30203703, 0.07073075, 0.5350826 , 0.5438215 ], dtype=float32),\n",
       "  array([0.2176217 , 0.06772655, 0.5349763 , 0.5010747 ], dtype=float32),\n",
       "  array([0.24356411, 0.07036656, 0.535048  , 0.5273227 ], dtype=float32),\n",
       "  array([0.21209572, 0.06345221, 0.53502405, 0.4916283 ], dtype=float32),\n",
       "  array([0.19412129, 0.061368  , 0.53501356, 0.48431244], dtype=float32),\n",
       "  array([0.21302737, 0.06206747, 0.5348411 , 0.48830983], dtype=float32),\n",
       "  array([0.21722195, 0.06627899, 0.53492254, 0.48915726], dtype=float32),\n",
       "  array([0.20202564, 0.06108207, 0.5346851 , 0.49201185], dtype=float32),\n",
       "  array([0.29737234, 0.09532879, 0.53473276, 0.5282413 ], dtype=float32),\n",
       "  array([0.21138103, 0.05988957, 0.5345419 , 0.47866917], dtype=float32),\n",
       "  array([0.91982555, 0.16932641, 0.5354964 , 0.98318   ], dtype=float32),\n",
       "  array([0.9180578 , 0.16846296, 0.5354842 , 0.98259556], dtype=float32),\n",
       "  array([0.91397536, 0.16137531, 0.5354    , 0.94734466], dtype=float32),\n",
       "  array([0.6148716 , 0.1297009 , 0.53501344, 0.87133664], dtype=float32),\n",
       "  array([0.50428694, 0.10545948, 0.5341885 , 0.745955  ], dtype=float32),\n",
       "  array([0.49544495, 0.09862005, 0.5335887 , 0.6771256 ], dtype=float32),\n",
       "  array([0.3358102 , 0.08903617, 0.53282917, 0.6334326 ], dtype=float32),\n",
       "  array([0.5092499 , 0.10721573, 0.5326204 , 0.7191564 ], dtype=float32),\n",
       "  array([0.5026705 , 0.10375673, 0.5319908 , 0.70223135], dtype=float32),\n",
       "  array([0.47213954, 0.09609935, 0.47438368, 0.69309086], dtype=float32),\n",
       "  array([0.3868507 , 0.08872669, 0.46525326, 0.65281147], dtype=float32),\n",
       "  array([0.45241362, 0.09734163, 0.46627286, 0.6227729 ], dtype=float32),\n",
       "  array([0.4690428 , 0.08099886, 0.44078642, 0.61171114], dtype=float32),\n",
       "  array([0.34712252, 0.08440758, 0.4657282 , 0.61719406], dtype=float32),\n",
       "  array([0.3253629 , 0.07682358, 0.43410087, 0.59323305], dtype=float32),\n",
       "  array([0.37665   , 0.0834332 , 0.46561334, 0.59168434], dtype=float32),\n",
       "  array([0.3106832 , 0.0723912 , 0.45047358, 0.5596784 ], dtype=float32),\n",
       "  array([0.3479374 , 0.06879445, 0.48564562, 0.5499945 ], dtype=float32),\n",
       "  array([0.28982934, 0.07082933, 0.3775475 , 0.5404738 ], dtype=float32),\n",
       "  array([0.30882412, 0.06739634, 0.3347531 , 0.5496102 ], dtype=float32),\n",
       "  array([0.3751613 , 0.07567697, 0.33499762, 0.55320036], dtype=float32),\n",
       "  array([0.3221011 , 0.06313099, 0.3234137 , 0.53414154], dtype=float32),\n",
       "  array([0.85390747, 0.17575523, 0.53535694, 0.97160393], dtype=float32),\n",
       "  array([0.41780412, 0.08508439, 0.4041683 , 0.61587805], dtype=float32),\n",
       "  array([0.36319008, 0.07016576, 0.3492722 , 0.55531687], dtype=float32),\n",
       "  array([0.3304218 , 0.06417655, 0.31778696, 0.53885156], dtype=float32),\n",
       "  array([0.35030875, 0.06603595, 0.31574425, 0.5411957 ], dtype=float32),\n",
       "  array([0.3731366 , 0.06075786, 0.30281815, 0.54320234], dtype=float32),\n",
       "  array([0.33906102, 0.06705126, 0.3450909 , 0.570453  ], dtype=float32),\n",
       "  array([0.45589456, 0.10206711, 0.5050474 , 0.63913363], dtype=float32),\n",
       "  array([0.2941489 , 0.06197305, 0.30049103, 0.52079934], dtype=float32),\n",
       "  array([0.4921261 , 0.08988608, 0.37021518, 0.68253255], dtype=float32),\n",
       "  array([0.32050782, 0.05968151, 0.29081947, 0.5266394 ], dtype=float32),\n",
       "  array([0.3162625 , 0.07283287, 0.29335457, 0.53349394], dtype=float32),\n",
       "  array([0.29593444, 0.05631677, 0.28039294, 0.5162438 ], dtype=float32),\n",
       "  array([0.29684746, 0.0585007 , 0.28525615, 0.52043205], dtype=float32),\n",
       "  array([0.3303773 , 0.0629724 , 0.28424406, 0.5149631 ], dtype=float32),\n",
       "  array([0.24804407, 0.05575008, 0.26118502, 0.4987471 ], dtype=float32),\n",
       "  array([0.24063648, 0.06129211, 0.26939982, 0.5188816 ], dtype=float32),\n",
       "  array([0.2562117 , 0.05366311, 0.2762426 , 0.50429076], dtype=float32),\n",
       "  array([0.2583754 , 0.0532276 , 0.26151013, 0.49199203], dtype=float32),\n",
       "  array([0.90518093, 0.13151243, 0.53551453, 0.9739659 ], dtype=float32),\n",
       "  array([0.5183092 , 0.10331272, 0.47613686, 0.6647066 ], dtype=float32),\n",
       "  array([0.40160355, 0.07357213, 0.37441456, 0.5804932 ], dtype=float32),\n",
       "  array([0.35374773, 0.07360311, 0.35670206, 0.58764017], dtype=float32),\n",
       "  array([0.3441067 , 0.06888884, 0.33313414, 0.54485524], dtype=float32),\n",
       "  array([0.30192083, 0.06296088, 0.3205818 , 0.5188988 ], dtype=float32),\n",
       "  array([0.2561546 , 0.05442295, 0.30171764, 0.4980031 ], dtype=float32),\n",
       "  array([0.2941832 , 0.06775106, 0.32282084, 0.50788635], dtype=float32),\n",
       "  array([0.23353696, 0.0518563 , 0.28964013, 0.48797846], dtype=float32),\n",
       "  array([0.39800304, 0.05036372, 0.28567004, 0.48511285], dtype=float32),\n",
       "  array([0.24373937, 0.05015939, 0.28363347, 0.48279428], dtype=float32),\n",
       "  array([0.23731554, 0.0559316 , 0.28814492, 0.4930243 ], dtype=float32),\n",
       "  array([0.19871207, 0.04938313, 0.2867071 , 0.4861531 ], dtype=float32),\n",
       "  array([0.23849306, 0.05344326, 0.30096415, 0.47953823], dtype=float32),\n",
       "  array([0.1687264 , 0.0483818 , 0.27397248, 0.4622123 ], dtype=float32),\n",
       "  array([0.20862179, 0.04995466, 0.28700185, 0.46879292], dtype=float32),\n",
       "  array([0.2099752 , 0.07156236, 0.2985658 , 0.523125  ], dtype=float32),\n",
       "  array([0.19809777, 0.05281654, 0.3050737 , 0.4890599 ], dtype=float32),\n",
       "  array([0.17321809, 0.05302674, 0.29116657, 0.45660898], dtype=float32),\n",
       "  array([0.18666498, 0.04730162, 0.27541015, 0.4900634 ], dtype=float32),\n",
       "  array([0.1912975 , 0.04973776, 0.26866102, 0.4507693 ], dtype=float32),\n",
       "  array([0.24364065, 0.06519596, 0.26690006, 0.45531297], dtype=float32),\n",
       "  array([0.37169006, 0.0504273 , 0.2807218 , 0.4530133 ], dtype=float32),\n",
       "  array([0.21132846, 0.05201539, 0.2740275 , 0.44768524], dtype=float32),\n",
       "  array([0.23220842, 0.06894367, 0.5350068 , 0.4822486 ], dtype=float32),\n",
       "  array([0.15902588, 0.06101489, 0.5353519 , 0.45919004], dtype=float32),\n",
       "  array([0.15975182, 0.05364195, 0.530829  , 0.47246283], dtype=float32),\n",
       "  array([0.21542062, 0.05716688, 0.4641688 , 0.4745084 ], dtype=float32),\n",
       "  array([0.15204844, 0.04706164, 0.4245063 , 0.45071197], dtype=float32),\n",
       "  array([0.19529437, 0.04619865, 0.3948592 , 0.44283476], dtype=float32),\n",
       "  array([0.20950049, 0.04813379, 0.41954803, 0.44358268], dtype=float32),\n",
       "  array([0.13476524, 0.04432329, 0.38682303, 0.42524722], dtype=float32),\n",
       "  array([0.23874426, 0.07636088, 0.534178  , 0.5038894 ], dtype=float32),\n",
       "  array([0.21042512, 0.05544858, 0.48634717, 0.45988172], dtype=float32),\n",
       "  array([0.17425911, 0.04460708, 0.39534262, 0.42995557], dtype=float32),\n",
       "  array([0.14096189, 0.04366837, 0.38667157, 0.42151296], dtype=float32),\n",
       "  array([0.4400404 , 0.08821201, 0.5314885 , 0.56773335], dtype=float32),\n",
       "  array([0.31146875, 0.05517465, 0.4619263 , 0.46512768], dtype=float32),\n",
       "  array([0.15405026, 0.04544448, 0.39543197, 0.44523415], dtype=float32),\n",
       "  array([0.13744882, 0.04332069, 0.36370987, 0.42943352], dtype=float32),\n",
       "  array([0.13071091, 0.04359173, 0.39810166, 0.42287153], dtype=float32),\n",
       "  array([0.141153  , 0.04142633, 0.39125267, 0.41139707], dtype=float32),\n",
       "  array([0.14566894, 0.04090092, 0.41611663, 0.40887952], dtype=float32),\n",
       "  array([0.4495154 , 0.10157271, 0.4919267 , 0.67033494], dtype=float32),\n",
       "  array([0.15057053, 0.04125613, 0.36176413, 0.40992847], dtype=float32),\n",
       "  array([0.5478173 , 0.17155063, 0.5356789 , 0.9078563 ], dtype=float32),\n",
       "  array([0.18088531, 0.0607003 , 0.36779997, 0.47756472], dtype=float32),\n",
       "  array([0.16033341, 0.05071098, 0.39118773, 0.46236417], dtype=float32),\n",
       "  array([0.148968  , 0.04543542, 0.40401316, 0.44770646], dtype=float32),\n",
       "  array([0.13493928, 0.04305722, 0.33843   , 0.4348585 ], dtype=float32),\n",
       "  array([0.18914291, 0.07393229, 0.42051288, 0.45942178], dtype=float32),\n",
       "  array([0.12412325, 0.0434559 , 0.36692208, 0.41751483], dtype=float32),\n",
       "  array([0.12636684, 0.04024706, 0.3557624 , 0.4119007 ], dtype=float32),\n",
       "  array([0.12973389, 0.04048453, 0.2544838 , 0.40687302], dtype=float32),\n",
       "  array([0.11971941, 0.04048466, 0.267131  , 0.40163046], dtype=float32),\n",
       "  array([0.115716  , 0.03863224, 0.23813525, 0.3962161 ], dtype=float32),\n",
       "  array([0.12597299, 0.03809521, 0.22519436, 0.39183477], dtype=float32),\n",
       "  array([0.11570823, 0.03815775, 0.22268082, 0.39035538], dtype=float32),\n",
       "  array([0.12375914, 0.03779279, 0.21953022, 0.38963607], dtype=float32),\n",
       "  array([0.1153826 , 0.03807854, 0.21490106, 0.3888    ], dtype=float32),\n",
       "  array([0.12712845, 0.03902937, 0.2384421 , 0.38539925], dtype=float32),\n",
       "  array([0.15282251, 0.05067618, 0.26439166, 0.44064638], dtype=float32),\n",
       "  array([0.12813185, 0.04244375, 0.22441   , 0.40128312], dtype=float32),\n",
       "  array([0.11839633, 0.03888561, 0.21465343, 0.39147457], dtype=float32),\n",
       "  array([0.12084208, 0.03736018, 0.21781492, 0.38561657], dtype=float32),\n",
       "  array([0.13436575, 0.03932358, 0.22541939, 0.39348453], dtype=float32),\n",
       "  array([0.12138388, 0.03847684, 0.21438049, 0.3926645 ], dtype=float32),\n",
       "  array([0.11499131, 0.03722721, 0.21564959, 0.38442126], dtype=float32),\n",
       "  array([0.11804549, 0.03763387, 0.2135548 , 0.38446164], dtype=float32),\n",
       "  array([0.1133754 , 0.03676856, 0.2139969 , 0.38209072], dtype=float32),\n",
       "  array([0.11309359, 0.03722663, 0.20729038, 0.37678468], dtype=float32),\n",
       "  array([0.11532611, 0.03665407, 0.22459471, 0.37701818], dtype=float32),\n",
       "  array([0.11848728, 0.0375036 , 0.22661063, 0.3780926 ], dtype=float32),\n",
       "  array([0.11521688, 0.0381554 , 0.22361635, 0.38324836], dtype=float32),\n",
       "  array([0.1085088 , 0.0360926 , 0.20450535, 0.37327203], dtype=float32),\n",
       "  array([0.11115737, 0.03600241, 0.21779895, 0.3729496 ], dtype=float32),\n",
       "  array([0.1105075 , 0.03584303, 0.20488277, 0.37020653], dtype=float32),\n",
       "  array([0.11405001, 0.03608293, 0.21014176, 0.3706609 ], dtype=float32),\n",
       "  array([0.10841823, 0.03682473, 0.20307547, 0.37006268], dtype=float32),\n",
       "  array([0.10689216, 0.03569704, 0.20868249, 0.371508  ], dtype=float32),\n",
       "  array([0.10844272, 0.03676607, 0.2059583 , 0.3743938 ], dtype=float32),\n",
       "  array([0.10894734, 0.03520323, 0.20394948, 0.36507353], dtype=float32),\n",
       "  array([0.10676927, 0.03548885, 0.2000483 , 0.36458623], dtype=float32),\n",
       "  array([0.1057042 , 0.03566369, 0.20208979, 0.36792508], dtype=float32),\n",
       "  array([0.10197376, 0.03543474, 0.201373  , 0.3652528 ], dtype=float32),\n",
       "  array([0.10322416, 0.03502913, 0.20287995, 0.36314413], dtype=float32),\n",
       "  array([0.10072166, 0.03555107, 0.20309475, 0.3636593 ], dtype=float32),\n",
       "  array([0.10126651, 0.03543091, 0.20498125, 0.36299083], dtype=float32),\n",
       "  array([0.09983113, 0.03477984, 0.20371927, 0.36207268], dtype=float32),\n",
       "  array([0.10232058, 0.03641805, 0.21968025, 0.364423  ], dtype=float32),\n",
       "  array([0.10142706, 0.03522065, 0.2001969 , 0.36702305], dtype=float32),\n",
       "  array([0.10136756, 0.03483417, 0.19875047, 0.36204207], dtype=float32),\n",
       "  array([0.1006173 , 0.03512922, 0.19945325, 0.3611625 ], dtype=float32),\n",
       "  array([0.1021532 , 0.03771272, 0.21228904, 0.37766096], dtype=float32),\n",
       "  array([0.10191187, 0.03443761, 0.1987161 , 0.35970113], dtype=float32),\n",
       "  array([0.10891706, 0.03457705, 0.19810307, 0.35940433], dtype=float32),\n",
       "  array([0.10373054, 0.03627533, 0.20193546, 0.36356086], dtype=float32),\n",
       "  array([0.09925485, 0.03508611, 0.20196354, 0.36342674], dtype=float32),\n",
       "  array([0.09713539, 0.03455101, 0.19655845, 0.35775277], dtype=float32),\n",
       "  array([0.1132413 , 0.03753156, 0.20063807, 0.365626  ], dtype=float32),\n",
       "  array([0.10166258, 0.03525404, 0.19794008, 0.3599997 ], dtype=float32),\n",
       "  array([0.09892119, 0.03479192, 0.19854619, 0.35855627], dtype=float32),\n",
       "  array([0.09819869, 0.0345658 , 0.19904287, 0.36032405], dtype=float32),\n",
       "  array([0.10050346, 0.03447441, 0.19739217, 0.3586598 ], dtype=float32),\n",
       "  array([0.10324558, 0.03439488, 0.20001002, 0.36106637], dtype=float32),\n",
       "  array([0.11847456, 0.03452056, 0.19600904, 0.36098364], dtype=float32),\n",
       "  array([0.10407619, 0.03431948, 0.19779672, 0.35730526], dtype=float32),\n",
       "  array([0.10495996, 0.03576042, 0.2004937 , 0.3580382 ], dtype=float32),\n",
       "  array([0.09796207, 0.03427173, 0.20080721, 0.35685012], dtype=float32),\n",
       "  array([0.10134278, 0.03454288, 0.19796452, 0.35920843], dtype=float32),\n",
       "  array([0.1042598 , 0.03440747, 0.19806704, 0.3566642 ], dtype=float32),\n",
       "  array([0.09965317, 0.03455321, 0.1982602 , 0.35604343], dtype=float32),\n",
       "  array([0.09660657, 0.03414682, 0.1987657 , 0.3565996 ], dtype=float32),\n",
       "  array([0.10088168, 0.03451938, 0.1984037 , 0.35871255], dtype=float32),\n",
       "  array([0.09661841, 0.03429511, 0.19840816, 0.3575612 ], dtype=float32),\n",
       "  array([0.09799345, 0.03565897, 0.20018716, 0.36036035], dtype=float32),\n",
       "  array([0.09755525, 0.03413804, 0.195984  , 0.35543913], dtype=float32),\n",
       "  array([0.09560814, 0.03403245, 0.19762345, 0.35511678], dtype=float32),\n",
       "  array([0.09595091, 0.03404173, 0.19638868, 0.3563736 ], dtype=float32),\n",
       "  array([0.09662797, 0.03461607, 0.19896127, 0.35749277], dtype=float32),\n",
       "  array([0.09728215, 0.03435133, 0.19722521, 0.35462418], dtype=float32),\n",
       "  array([0.09679836, 0.03398197, 0.1957337 , 0.35463452], dtype=float32),\n",
       "  array([0.09847782, 0.03410093, 0.19534764, 0.35524103], dtype=float32),\n",
       "  array([0.09672329, 0.03431312, 0.1973818 , 0.35519916], dtype=float32),\n",
       "  array([0.09570836, 0.03396737, 0.19624415, 0.3537728 ], dtype=float32),\n",
       "  array([0.0959192 , 0.03380559, 0.19608654, 0.3543079 ], dtype=float32),\n",
       "  array([0.09612538, 0.03384039, 0.1964075 , 0.35609746], dtype=float32),\n",
       "  array([0.09556871, 0.03386676, 0.19636974, 0.35327563], dtype=float32),\n",
       "  array([0.09515946, 0.03415124, 0.19743803, 0.35344696], dtype=float32),\n",
       "  array([0.0951907 , 0.03387758, 0.19722733, 0.35350108], dtype=float32),\n",
       "  array([0.09701524, 0.03386955, 0.19526272, 0.3552704 ], dtype=float32),\n",
       "  array([0.0945752 , 0.03375696, 0.19523193, 0.3528914 ], dtype=float32),\n",
       "  array([0.09501095, 0.0338702 , 0.1961973 , 0.3545215 ], dtype=float32),\n",
       "  array([0.09480168, 0.03381734, 0.19517797, 0.35349566], dtype=float32),\n",
       "  array([0.09693874, 0.03400332, 0.19541383, 0.3563633 ], dtype=float32),\n",
       "  array([0.09496146, 0.03364303, 0.19521798, 0.353165  ], dtype=float32),\n",
       "  array([0.09572972, 0.03390379, 0.19608757, 0.35293972], dtype=float32),\n",
       "  array([0.09593091, 0.03559049, 0.20187214, 0.36226133], dtype=float32),\n",
       "  array([0.09458202, 0.03375627, 0.19490208, 0.35341585], dtype=float32),\n",
       "  array([0.09487758, 0.03384884, 0.19550952, 0.35483688], dtype=float32),\n",
       "  array([0.09448507, 0.03376887, 0.19509006, 0.35496718], dtype=float32),\n",
       "  array([0.09437605, 0.03373804, 0.19540161, 0.3543877 ], dtype=float32),\n",
       "  array([0.09469666, 0.03372091, 0.19548394, 0.35253283], dtype=float32),\n",
       "  array([0.09452045, 0.03374605, 0.19512452, 0.35305208], dtype=float32),\n",
       "  array([0.09460983, 0.03382267, 0.1953259 , 0.35244587], dtype=float32),\n",
       "  array([0.09459909, 0.03383056, 0.19605783, 0.3525693 ], dtype=float32),\n",
       "  array([0.09467087, 0.03377176, 0.19539838, 0.35326824], dtype=float32),\n",
       "  array([0.09403923, 0.03371267, 0.19470333, 0.35215384], dtype=float32),\n",
       "  array([0.09477913, 0.03368158, 0.19446342, 0.35311785], dtype=float32),\n",
       "  array([0.094737  , 0.03374761, 0.1951074 , 0.3523535 ], dtype=float32),\n",
       "  array([0.09459198, 0.0337374 , 0.19492693, 0.35348195], dtype=float32),\n",
       "  array([0.09408073, 0.03376062, 0.19480115, 0.3518464 ], dtype=float32),\n",
       "  array([0.09423561, 0.03379244, 0.19496736, 0.35223275], dtype=float32),\n",
       "  array([0.09466655, 0.03371105, 0.19479977, 0.35226613], dtype=float32),\n",
       "  array([0.09503913, 0.03373661, 0.1950531 , 0.35230103], dtype=float32),\n",
       "  array([0.09429915, 0.03374558, 0.19518057, 0.3517157 ], dtype=float32),\n",
       "  array([0.09440632, 0.03383307, 0.19537927, 0.35230765], dtype=float32),\n",
       "  array([0.09417968, 0.03372644, 0.19474171, 0.35194236], dtype=float32),\n",
       "  array([0.0938436 , 0.03373541, 0.19514668, 0.35254246], dtype=float32),\n",
       "  array([0.09389495, 0.03381964, 0.1946966 , 0.35184544], dtype=float32),\n",
       "  array([0.09417024, 0.03373725, 0.1947891 , 0.3519746 ], dtype=float32),\n",
       "  array([0.09392385, 0.03378975, 0.19483204, 0.3515753 ], dtype=float32),\n",
       "  array([0.09439339, 0.03374639, 0.19472802, 0.35164544], dtype=float32),\n",
       "  array([0.09408727, 0.03376812, 0.19477004, 0.35207918], dtype=float32),\n",
       "  array([0.09392069, 0.03374594, 0.19499032, 0.3521446 ], dtype=float32),\n",
       "  array([0.09385296, 0.03379674, 0.1947363 , 0.35238615], dtype=float32),\n",
       "  array([0.09396023, 0.03377593, 0.19468309, 0.35317433], dtype=float32),\n",
       "  array([0.09382264, 0.03379292, 0.19466624, 0.3515932 ], dtype=float32),\n",
       "  array([0.09373862, 0.03380661, 0.19458914, 0.3514556 ], dtype=float32),\n",
       "  array([0.09368018, 0.03381244, 0.19471431, 0.35135224], dtype=float32),\n",
       "  array([0.09365856, 0.03378389, 0.19464074, 0.35157773], dtype=float32),\n",
       "  array([0.093647  , 0.03377219, 0.19458348, 0.35174057], dtype=float32),\n",
       "  array([0.09376967, 0.03376945, 0.1947214 , 0.3523226 ], dtype=float32),\n",
       "  array([0.09383421, 0.03377944, 0.19467883, 0.35242882], dtype=float32),\n",
       "  array([0.09372339, 0.03380649, 0.19453014, 0.35184386], dtype=float32),\n",
       "  array([0.09375264, 0.03376944, 0.19456144, 0.35179988], dtype=float32),\n",
       "  array([0.09380583, 0.03381635, 0.19445631, 0.3516335 ], dtype=float32),\n",
       "  array([0.09373628, 0.03379537, 0.19454956, 0.3518099 ], dtype=float32),\n",
       "  array([0.09370089, 0.03378944, 0.19457218, 0.35170886], dtype=float32),\n",
       "  array([0.09378228, 0.03378085, 0.19455244, 0.35221335], dtype=float32),\n",
       "  array([0.09380183, 0.03377974, 0.19455795, 0.3523976 ], dtype=float32),\n",
       "  array([0.09379412, 0.0337768 , 0.19450511, 0.3518515 ], dtype=float32),\n",
       "  array([0.0937802 , 0.03377894, 0.19446044, 0.3517937 ], dtype=float32),\n",
       "  array([0.09376421, 0.03377975, 0.19446625, 0.35177025], dtype=float32),\n",
       "  array([0.0937636 , 0.03378079, 0.19445246, 0.35177612], dtype=float32),\n",
       "  array([0.09377886, 0.03378137, 0.19446065, 0.3517505 ], dtype=float32),\n",
       "  array([0.09376703, 0.03378438, 0.19445448, 0.35171396], dtype=float32),\n",
       "  array([0.09377611, 0.03378492, 0.19445434, 0.35173333], dtype=float32),\n",
       "  array([0.09377362, 0.03378436, 0.19445245, 0.3517329 ], dtype=float32),\n",
       "  array([0.09377079, 0.03378459, 0.19445114, 0.35172778], dtype=float32)],\n",
       " 'train_acc': [array([0.9351414 , 0.13507687, 0.54403114, 0.995415  ], dtype=float32),\n",
       "  array([0.9291478 , 0.09799126, 0.54390246, 0.99469334], dtype=float32),\n",
       "  array([0.6150214 , 0.08938453, 0.5438711 , 0.6415948 ], dtype=float32),\n",
       "  array([0.53215975, 0.07993674, 0.54382527, 0.5734194 ], dtype=float32),\n",
       "  array([0.39597136, 0.07436501, 0.5437921 , 0.5425709 ], dtype=float32),\n",
       "  array([0.25736102, 0.07508644, 0.54375654, 0.531862  ], dtype=float32),\n",
       "  array([0.24380389, 0.06996223, 0.5437426 , 0.5133093 ], dtype=float32),\n",
       "  array([0.25381765, 0.06885397, 0.5437203 , 0.51624405], dtype=float32),\n",
       "  array([0.2295468 , 0.06924623, 0.5436667 , 0.50850517], dtype=float32),\n",
       "  array([0.30257693, 0.07043537, 0.54361814, 0.5488575 ], dtype=float32),\n",
       "  array([0.20643733, 0.068878  , 0.543517  , 0.5071948 ], dtype=float32),\n",
       "  array([0.24549083, 0.07155021, 0.5435977 , 0.5299164 ], dtype=float32),\n",
       "  array([0.20297304, 0.06387015, 0.54358196, 0.49754134], dtype=float32),\n",
       "  array([0.18696715, 0.06216102, 0.5435654 , 0.4921538 ], dtype=float32),\n",
       "  array([0.2036446 , 0.06160703, 0.5433896 , 0.4928322 ], dtype=float32),\n",
       "  array([0.21387939, 0.06663511, 0.54347175, 0.49721763], dtype=float32),\n",
       "  array([0.19557041, 0.06212484, 0.5432473 , 0.49854636], dtype=float32),\n",
       "  array([0.30016354, 0.09661348, 0.5432881 , 0.5336583 ], dtype=float32),\n",
       "  array([0.20464021, 0.06017815, 0.5430986 , 0.48435158], dtype=float32),\n",
       "  array([0.9357058 , 0.17316677, 0.5440876 , 0.99290514], dtype=float32),\n",
       "  array([0.9338051 , 0.17223316, 0.5440753 , 0.99252766], dtype=float32),\n",
       "  array([0.9295916, 0.1656013, 0.5440006, 0.9580273], dtype=float32),\n",
       "  array([0.63350415, 0.13581581, 0.54364574, 0.8815429 ], dtype=float32),\n",
       "  array([0.50605285, 0.10871948, 0.542781  , 0.74941987], dtype=float32),\n",
       "  array([0.4977967 , 0.09941234, 0.54214996, 0.68315166], dtype=float32),\n",
       "  array([0.34332344, 0.08950517, 0.541333  , 0.6360171 ], dtype=float32),\n",
       "  array([0.5062264 , 0.10861786, 0.54100406, 0.71626484], dtype=float32),\n",
       "  array([0.49888006, 0.10606693, 0.5405361 , 0.7018987 ], dtype=float32),\n",
       "  array([0.46758255, 0.09755618, 0.4831602 , 0.68430275], dtype=float32),\n",
       "  array([0.38408023, 0.0895406 , 0.46976516, 0.64348483], dtype=float32),\n",
       "  array([0.45225856, 0.09757401, 0.46986833, 0.6180575 ], dtype=float32),\n",
       "  array([0.475025  , 0.08146159, 0.44162732, 0.60918754], dtype=float32),\n",
       "  array([0.33529222, 0.08200534, 0.4719573 , 0.60723907], dtype=float32),\n",
       "  array([0.3251332 , 0.0752181 , 0.43344104, 0.58777183], dtype=float32),\n",
       "  array([0.37267354, 0.08420852, 0.47094482, 0.5816767 ], dtype=float32),\n",
       "  array([0.31683642, 0.07334496, 0.45195225, 0.5585043 ], dtype=float32),\n",
       "  array([0.3769696 , 0.06888633, 0.49159962, 0.55593884], dtype=float32),\n",
       "  array([0.29359365, 0.07375536, 0.3708276 , 0.5670674 ], dtype=float32),\n",
       "  array([0.30208847, 0.06889974, 0.3346692 , 0.5574322 ], dtype=float32),\n",
       "  array([0.36476535, 0.07547755, 0.3335022 , 0.57133293], dtype=float32),\n",
       "  array([0.31732154, 0.06281956, 0.31328776, 0.5488203 ], dtype=float32),\n",
       "  array([0.86916625, 0.1809624 , 0.5439716 , 0.9817342 ], dtype=float32),\n",
       "  array([0.4201923 , 0.08640219, 0.40095568, 0.6245116 ], dtype=float32),\n",
       "  array([0.36938965, 0.07052895, 0.3445334 , 0.57125604], dtype=float32),\n",
       "  array([0.33294827, 0.06360649, 0.31078258, 0.5479306 ], dtype=float32),\n",
       "  array([0.3488992 , 0.06411123, 0.30654716, 0.5464748 ], dtype=float32),\n",
       "  array([0.37278134, 0.06281745, 0.3061893 , 0.5500536 ], dtype=float32),\n",
       "  array([0.33678794, 0.06831724, 0.3496645 , 0.57127416], dtype=float32),\n",
       "  array([0.464298  , 0.1074124 , 0.51046973, 0.6474056 ], dtype=float32),\n",
       "  array([0.2879404 , 0.06022545, 0.28944716, 0.5278594 ], dtype=float32),\n",
       "  array([0.48042464, 0.08822267, 0.37101197, 0.70070475], dtype=float32),\n",
       "  array([0.30706158, 0.06000353, 0.2888543 , 0.54135865], dtype=float32),\n",
       "  array([0.3073748 , 0.07281461, 0.29177228, 0.5486682 ], dtype=float32),\n",
       "  array([0.2969318 , 0.0566122 , 0.2743112 , 0.52349293], dtype=float32),\n",
       "  array([0.28516823, 0.05974554, 0.28192163, 0.5343341 ], dtype=float32),\n",
       "  array([0.3255477 , 0.0625583 , 0.2797664 , 0.52742076], dtype=float32),\n",
       "  array([0.24837454, 0.05589897, 0.25777373, 0.50947857], dtype=float32),\n",
       "  array([0.24054079, 0.06210441, 0.26798502, 0.5250717 ], dtype=float32),\n",
       "  array([0.2603003 , 0.05513409, 0.27780315, 0.5169647 ], dtype=float32),\n",
       "  array([0.26292506, 0.0540038 , 0.25810114, 0.50080436], dtype=float32),\n",
       "  array([0.91947746, 0.13368985, 0.5441192 , 0.9837568 ], dtype=float32),\n",
       "  array([0.53095126, 0.10444457, 0.48348996, 0.6713057 ], dtype=float32),\n",
       "  array([0.3982236 , 0.07416885, 0.37533188, 0.58544475], dtype=float32),\n",
       "  array([0.35464755, 0.07303656, 0.35317442, 0.59408313], dtype=float32),\n",
       "  array([0.3402389 , 0.06764802, 0.329485  , 0.5448927 ], dtype=float32),\n",
       "  array([0.29979753, 0.06268044, 0.31924668, 0.5294333 ], dtype=float32),\n",
       "  array([0.25360915, 0.05475482, 0.2996283 , 0.5037145 ], dtype=float32),\n",
       "  array([0.2967974 , 0.06715816, 0.3226326 , 0.511798  ], dtype=float32),\n",
       "  array([0.23265207, 0.05191853, 0.28729036, 0.49298126], dtype=float32),\n",
       "  array([0.41269794, 0.05060288, 0.28351524, 0.4909771 ], dtype=float32),\n",
       "  array([0.24518539, 0.05049868, 0.28206658, 0.48876202], dtype=float32),\n",
       "  array([0.23946974, 0.05718658, 0.28664342, 0.49947885], dtype=float32),\n",
       "  array([0.19984399, 0.04977597, 0.28613946, 0.49044213], dtype=float32),\n",
       "  array([0.24047537, 0.05322907, 0.299813  , 0.48339123], dtype=float32),\n",
       "  array([0.16894355, 0.04934284, 0.27304363, 0.46910173], dtype=float32),\n",
       "  array([0.21211803, 0.05084935, 0.2857561 , 0.47762552], dtype=float32),\n",
       "  array([0.21079458, 0.07115238, 0.29855806, 0.5274284 ], dtype=float32),\n",
       "  array([0.20288946, 0.05327958, 0.30381054, 0.50157094], dtype=float32),\n",
       "  array([0.17216563, 0.05363774, 0.2900737 , 0.46034998], dtype=float32),\n",
       "  array([0.18672785, 0.04804844, 0.2749015 , 0.49980584], dtype=float32),\n",
       "  array([0.19164868, 0.0506644 , 0.26694643, 0.45961607], dtype=float32),\n",
       "  array([0.24459048, 0.06719071, 0.26726103, 0.4598234 ], dtype=float32),\n",
       "  array([0.3826623 , 0.05083052, 0.28123996, 0.45831236], dtype=float32),\n",
       "  array([0.20894092, 0.05240238, 0.27323112, 0.45317966], dtype=float32),\n",
       "  array([0.23444732, 0.07005423, 0.5435545 , 0.4898306 ], dtype=float32),\n",
       "  array([0.15736942, 0.06117747, 0.5439501 , 0.46193162], dtype=float32),\n",
       "  array([0.16183938, 0.05428189, 0.53911704, 0.47952378], dtype=float32),\n",
       "  array([0.2180538 , 0.05706928, 0.47372684, 0.4812886 ], dtype=float32),\n",
       "  array([0.15387443, 0.04739727, 0.43291038, 0.45745632], dtype=float32),\n",
       "  array([0.20342833, 0.04683976, 0.4050241 , 0.44995752], dtype=float32),\n",
       "  array([0.22189169, 0.04911249, 0.4246438 , 0.45143887], dtype=float32),\n",
       "  array([0.13619572, 0.04522592, 0.39908582, 0.43416682], dtype=float32),\n",
       "  array([0.24681473, 0.07711917, 0.54273593, 0.5112051 ], dtype=float32),\n",
       "  array([0.21449043, 0.05529035, 0.49385482, 0.46267095], dtype=float32),\n",
       "  array([0.17955507, 0.04508324, 0.4106958 , 0.43533957], dtype=float32),\n",
       "  array([0.14154397, 0.04394886, 0.39089075, 0.4284952 ], dtype=float32),\n",
       "  array([0.45157894, 0.08887728, 0.5403807 , 0.57342786], dtype=float32),\n",
       "  array([0.310763  , 0.05606442, 0.46333638, 0.471542  ], dtype=float32),\n",
       "  array([0.15861554, 0.0462108 , 0.4075342 , 0.45094135], dtype=float32),\n",
       "  array([0.14075221, 0.04404685, 0.3727756 , 0.43814123], dtype=float32),\n",
       "  array([0.13507035, 0.04437295, 0.4060323 , 0.43197736], dtype=float32),\n",
       "  array([0.14517999, 0.04233668, 0.40384376, 0.4215037 ], dtype=float32),\n",
       "  array([0.14999641, 0.04157406, 0.42444226, 0.41818297], dtype=float32),\n",
       "  array([0.44133505, 0.10500743, 0.49783078, 0.66655004], dtype=float32),\n",
       "  array([0.15800379, 0.04179439, 0.373138  , 0.42014423], dtype=float32),\n",
       "  array([0.5628264 , 0.17564118, 0.5443148 , 0.9127849 ], dtype=float32),\n",
       "  array([0.18476205, 0.06109186, 0.3708378 , 0.48280272], dtype=float32),\n",
       "  array([0.1632292 , 0.05186367, 0.40190318, 0.46802533], dtype=float32),\n",
       "  array([0.14942841, 0.04597067, 0.41123718, 0.45581678], dtype=float32),\n",
       "  array([0.13605398, 0.04366563, 0.34668425, 0.43935058], dtype=float32),\n",
       "  array([0.18017624, 0.0728986 , 0.42998257, 0.4624986 ], dtype=float32),\n",
       "  array([0.12424249, 0.04443006, 0.37449917, 0.42434818], dtype=float32),\n",
       "  array([0.12762369, 0.04085296, 0.36434853, 0.418275  ], dtype=float32),\n",
       "  array([0.12938556, 0.04096138, 0.2520649 , 0.4144625 ], dtype=float32),\n",
       "  array([0.1197063 , 0.04100536, 0.26636454, 0.4093483 ], dtype=float32),\n",
       "  array([0.11646222, 0.0392806 , 0.2364145 , 0.4090653 ], dtype=float32),\n",
       "  array([0.12689264, 0.03877385, 0.22199163, 0.4033171 ], dtype=float32),\n",
       "  array([0.11694388, 0.03878479, 0.22072779, 0.40122396], dtype=float32),\n",
       "  array([0.12570085, 0.03840143, 0.21600975, 0.39968547], dtype=float32),\n",
       "  array([0.11548327, 0.03845087, 0.21291952, 0.39806688], dtype=float32),\n",
       "  array([0.12771674, 0.03950497, 0.23630607, 0.39484596], dtype=float32),\n",
       "  array([0.15747887, 0.05100144, 0.26408476, 0.44861886], dtype=float32),\n",
       "  array([0.1323246 , 0.04367806, 0.22300074, 0.4140098 ], dtype=float32),\n",
       "  array([0.12294119, 0.03982136, 0.21207772, 0.40258935], dtype=float32),\n",
       "  array([0.12212921, 0.03832373, 0.21532184, 0.39728203], dtype=float32),\n",
       "  array([0.13982482, 0.04024122, 0.2240144 , 0.40429997], dtype=float32),\n",
       "  array([0.12004577, 0.03925591, 0.21068932, 0.40202215], dtype=float32),\n",
       "  array([0.11330403, 0.03783734, 0.21215986, 0.39465913], dtype=float32),\n",
       "  array([0.11918081, 0.03817027, 0.21131612, 0.39445114], dtype=float32),\n",
       "  array([0.11129803, 0.03717764, 0.21151309, 0.39194968], dtype=float32),\n",
       "  array([0.11225919, 0.03797789, 0.20390688, 0.38743204], dtype=float32),\n",
       "  array([0.116032  , 0.03701488, 0.2214875 , 0.3876935 ], dtype=float32),\n",
       "  array([0.1182785 , 0.03784696, 0.22441867, 0.38540518], dtype=float32),\n",
       "  array([0.11402862, 0.03861708, 0.21958143, 0.39030564], dtype=float32),\n",
       "  array([0.10803865, 0.0364283 , 0.20053072, 0.38045472], dtype=float32),\n",
       "  array([0.11081103, 0.03616647, 0.21380927, 0.3806196 ], dtype=float32),\n",
       "  array([0.11079479, 0.03609674, 0.20033288, 0.37884143], dtype=float32),\n",
       "  array([0.11429379, 0.03645834, 0.20760679, 0.37954226], dtype=float32),\n",
       "  array([0.10743912, 0.03708465, 0.19937031, 0.37725544], dtype=float32),\n",
       "  array([0.10730944, 0.03578107, 0.20514503, 0.37972522], dtype=float32),\n",
       "  array([0.10931294, 0.03731509, 0.2028152 , 0.38053095], dtype=float32),\n",
       "  array([0.10937544, 0.03525957, 0.19948624, 0.37289244], dtype=float32),\n",
       "  array([0.10470621, 0.03546964, 0.1956521 , 0.37307045], dtype=float32),\n",
       "  array([0.10669544, 0.03568457, 0.19839779, 0.3760681 ], dtype=float32),\n",
       "  array([0.10041346, 0.03539701, 0.19683206, 0.37273824], dtype=float32),\n",
       "  array([0.10200532, 0.03505861, 0.19923826, 0.37131304], dtype=float32),\n",
       "  array([0.09972622, 0.03550704, 0.1992257 , 0.37168112], dtype=float32),\n",
       "  array([0.10155992, 0.03529907, 0.20071577, 0.37068814], dtype=float32),\n",
       "  array([0.09898027, 0.03461431, 0.19872421, 0.368003  ], dtype=float32),\n",
       "  array([0.10090397, 0.0368119 , 0.2164553 , 0.37242883], dtype=float32),\n",
       "  array([0.09890752, 0.03527019, 0.19518359, 0.37074855], dtype=float32),\n",
       "  array([0.10015567, 0.03465803, 0.1936758 , 0.36845824], dtype=float32),\n",
       "  array([0.09961975, 0.03476084, 0.19556446, 0.36715052], dtype=float32),\n",
       "  array([0.10108785, 0.03788925, 0.20921698, 0.38479683], dtype=float32),\n",
       "  array([0.10147761, 0.03434458, 0.19392703, 0.366412  ], dtype=float32),\n",
       "  array([0.10790303, 0.03450056, 0.19331719, 0.36632204], dtype=float32),\n",
       "  array([0.10131243, 0.03652648, 0.19730908, 0.37083474], dtype=float32),\n",
       "  array([0.09686849, 0.03493658, 0.19686794, 0.37005734], dtype=float32),\n",
       "  array([0.09479126, 0.03437317, 0.19178525, 0.36415803], dtype=float32),\n",
       "  array([0.11313365, 0.0376978 , 0.1959942 , 0.37167352], dtype=float32),\n",
       "  array([0.09998848, 0.03502095, 0.19247752, 0.36521268], dtype=float32),\n",
       "  array([0.09638968, 0.0345922 , 0.19360885, 0.36542153], dtype=float32),\n",
       "  array([0.09662199, 0.03429683, 0.19355494, 0.3680518 ], dtype=float32),\n",
       "  array([0.09829473, 0.03416925, 0.19176416, 0.36460534], dtype=float32),\n",
       "  array([0.10208298, 0.03415267, 0.19474126, 0.3673469 ], dtype=float32),\n",
       "  array([0.1171675 , 0.03417685, 0.1903356 , 0.36492056], dtype=float32),\n",
       "  array([0.10288589, 0.03406041, 0.19284253, 0.36421505], dtype=float32),\n",
       "  array([0.10117584, 0.03541492, 0.19516052, 0.36377054], dtype=float32),\n",
       "  array([0.09379716, 0.03374134, 0.19414948, 0.36131456], dtype=float32),\n",
       "  array([0.09779441, 0.0343926 , 0.19312862, 0.36539227], dtype=float32),\n",
       "  array([0.10176978, 0.03410879, 0.19290549, 0.36395404], dtype=float32),\n",
       "  array([0.09674954, 0.03408177, 0.19304097, 0.36207256], dtype=float32),\n",
       "  array([0.09408505, 0.0337173 , 0.19284351, 0.3619294 ], dtype=float32),\n",
       "  array([0.09836237, 0.03389539, 0.19292109, 0.36236235], dtype=float32),\n",
       "  array([0.09453195, 0.03372636, 0.192256  , 0.36497235], dtype=float32),\n",
       "  array([0.09428076, 0.03521413, 0.19482177, 0.3643215 ], dtype=float32),\n",
       "  array([0.09348552, 0.03355589, 0.19010758, 0.3594103 ], dtype=float32),\n",
       "  array([0.09185163, 0.03331196, 0.19060412, 0.35950178], dtype=float32),\n",
       "  array([0.0915043 , 0.03345408, 0.19095206, 0.36016065], dtype=float32),\n",
       "  array([0.09258179, 0.03393947, 0.19307575, 0.36209008], dtype=float32),\n",
       "  array([0.09388296, 0.0336243 , 0.19091001, 0.3590273 ], dtype=float32),\n",
       "  array([0.09240152, 0.03324347, 0.18947938, 0.35885212], dtype=float32),\n",
       "  array([0.09514879, 0.03329119, 0.18873422, 0.3588934 ], dtype=float32),\n",
       "  array([0.09141669, 0.03369122, 0.1907999 , 0.359837  ], dtype=float32),\n",
       "  array([0.09136598, 0.03345119, 0.18975838, 0.35902232], dtype=float32),\n",
       "  array([0.09127522, 0.03322036, 0.18960892, 0.35877833], dtype=float32),\n",
       "  array([0.09230823, 0.03312759, 0.19008404, 0.3594365 ], dtype=float32),\n",
       "  array([0.09083012, 0.03312233, 0.18942943, 0.35665032], dtype=float32),\n",
       "  array([0.09098126, 0.03349694, 0.19110812, 0.35850948], dtype=float32),\n",
       "  array([0.09050354, 0.03319644, 0.19078243, 0.3578629 ], dtype=float32),\n",
       "  array([0.09280679, 0.03305285, 0.18898772, 0.35844696], dtype=float32),\n",
       "  array([0.08960051, 0.0329836 , 0.18812063, 0.35588124], dtype=float32),\n",
       "  array([0.09079745, 0.0330557 , 0.1893031 , 0.35761034], dtype=float32),\n",
       "  array([0.0897074 , 0.03285346, 0.1878039 , 0.35602582], dtype=float32),\n",
       "  array([0.09168697, 0.0330681 , 0.18786754, 0.35889545], dtype=float32),\n",
       "  array([0.08944597, 0.03276842, 0.18737806, 0.35493088], dtype=float32),\n",
       "  array([0.09045914, 0.03327589, 0.18880184, 0.35654065], dtype=float32),\n",
       "  array([0.09156034, 0.03486151, 0.19539843, 0.3651585 ], dtype=float32),\n",
       "  array([0.0891298 , 0.03285761, 0.18729699, 0.3555136 ], dtype=float32),\n",
       "  array([0.08985116, 0.0328677 , 0.18814519, 0.35647985], dtype=float32),\n",
       "  array([0.08887029, 0.03272855, 0.18725723, 0.35605884], dtype=float32),\n",
       "  array([0.08919384, 0.03277911, 0.18806045, 0.35634962], dtype=float32),\n",
       "  array([0.08919255, 0.03271234, 0.18757188, 0.35417816], dtype=float32),\n",
       "  array([0.08886591, 0.03272431, 0.18760014, 0.35473537], dtype=float32),\n",
       "  array([0.08904889, 0.03279959, 0.18783724, 0.35496104], dtype=float32),\n",
       "  array([0.08862837, 0.03269986, 0.18863511, 0.35374323], dtype=float32),\n",
       "  array([0.08907511, 0.03271925, 0.18754712, 0.3550226 ], dtype=float32),\n",
       "  array([0.08879868, 0.03258686, 0.18658645, 0.3537885 ], dtype=float32),\n",
       "  array([0.08902003, 0.03258102, 0.1862795 , 0.35318008], dtype=float32),\n",
       "  array([0.08844087, 0.03268687, 0.18668844, 0.35356063], dtype=float32),\n",
       "  array([0.08894614, 0.03256788, 0.18656737, 0.35346133], dtype=float32),\n",
       "  array([0.08803083, 0.03248594, 0.18625852, 0.3527752 ], dtype=float32),\n",
       "  array([0.08834769, 0.03262322, 0.18687223, 0.3528766 ], dtype=float32),\n",
       "  array([0.08859812, 0.03258023, 0.18625961, 0.3535259 ], dtype=float32),\n",
       "  array([0.08916944, 0.03253316, 0.18646403, 0.3534231 ], dtype=float32),\n",
       "  array([0.08848341, 0.03252649, 0.18654981, 0.35309464], dtype=float32),\n",
       "  array([0.08847497, 0.03261978, 0.18715094, 0.3535764 ], dtype=float32),\n",
       "  array([0.08806791, 0.03244444, 0.18609233, 0.35284185], dtype=float32),\n",
       "  array([0.08799107, 0.03241147, 0.1861449 , 0.35283035], dtype=float32),\n",
       "  array([0.0880781 , 0.03248113, 0.18602693, 0.35245088], dtype=float32),\n",
       "  array([0.08793547, 0.03242315, 0.18598372, 0.35230726], dtype=float32),\n",
       "  array([0.08781639, 0.03244992, 0.18601005, 0.35212737], dtype=float32),\n",
       "  array([0.08811033, 0.03242535, 0.18580604, 0.3518065 ], dtype=float32),\n",
       "  array([0.08770695, 0.03240768, 0.18570165, 0.35156128], dtype=float32),\n",
       "  array([0.08761607, 0.03242574, 0.18593287, 0.3520864 ], dtype=float32),\n",
       "  array([0.08773856, 0.0324087 , 0.18592322, 0.3516218 ], dtype=float32),\n",
       "  array([0.08771454, 0.03237321, 0.18564805, 0.35168687], dtype=float32),\n",
       "  array([0.08772234, 0.03240959, 0.18572623, 0.35152617], dtype=float32),\n",
       "  array([0.08767134, 0.03239956, 0.18564011, 0.35147515], dtype=float32),\n",
       "  array([0.08769968, 0.03241198, 0.18576814, 0.35144475], dtype=float32),\n",
       "  array([0.08757457, 0.03238358, 0.18548144, 0.35146543], dtype=float32),\n",
       "  array([0.08770598, 0.03238072, 0.18554914, 0.35102865], dtype=float32),\n",
       "  array([0.08751633, 0.03239068, 0.18580231, 0.35122576], dtype=float32),\n",
       "  array([0.08749701, 0.03239373, 0.18558936, 0.35117868], dtype=float32),\n",
       "  array([0.08762433, 0.03237527, 0.18548146, 0.35094485], dtype=float32),\n",
       "  array([0.08750061, 0.03236727, 0.18565589, 0.35091728], dtype=float32),\n",
       "  array([0.0875309, 0.0323952, 0.1855165, 0.3508916], dtype=float32),\n",
       "  array([0.08747991, 0.03236362, 0.1854389 , 0.35076848], dtype=float32),\n",
       "  array([0.08744998, 0.03236651, 0.18538985, 0.35080704], dtype=float32),\n",
       "  array([0.08762758, 0.03239875, 0.18558545, 0.35121965], dtype=float32),\n",
       "  array([0.0874703 , 0.03237325, 0.18559127, 0.35088813], dtype=float32),\n",
       "  array([0.0874659 , 0.03237174, 0.18548687, 0.35074928], dtype=float32),\n",
       "  array([0.08748601, 0.03236753, 0.18545328, 0.3507378 ], dtype=float32),\n",
       "  array([0.08745229, 0.0323605 , 0.1854209 , 0.35071933], dtype=float32),\n",
       "  array([0.08743219, 0.03236021, 0.18541199, 0.3507031 ], dtype=float32),\n",
       "  array([0.08742878, 0.03236276, 0.18541051, 0.35070267], dtype=float32),\n",
       "  array([0.0874349 , 0.03236421, 0.18540931, 0.35070136], dtype=float32),\n",
       "  array([0.08743224, 0.03236349, 0.18540183, 0.35069853], dtype=float32),\n",
       "  array([0.08742999, 0.03236405, 0.1853991 , 0.35070014], dtype=float32),\n",
       "  array([0.08743151, 0.03236394, 0.18539888, 0.35069913], dtype=float32)],\n",
       " 'ys': array([[-1.1068422 ,  1.6963651 , -0.5735603 , -2.59298   ],\n",
       "        [-1.9189878 ,  1.7368743 ,  0.50924957, -3.2890606 ],\n",
       "        [-1.0813737 ,  1.6927959 , -0.11959975, -2.2212167 ],\n",
       "        ...,\n",
       "        [-2.54916   ,  1.6128898 , -0.25467768, -4.3898892 ],\n",
       "        [-2.3863654 ,  1.5706596 , -0.20527083, -4.026402  ],\n",
       "        [-2.037113  ,  1.4957746 , -0.97328293, -3.735905  ]],\n",
       "       dtype=float32),\n",
       " 'pred': array([[-1.1019063 ,  1.696851  , -0.39156792, -2.3447952 ],\n",
       "        [-1.9261551 ,  1.735735  ,  0.8233337 , -3.4223301 ],\n",
       "        [-1.1811926 ,  1.6944882 , -0.15710269, -2.326246  ],\n",
       "        ...,\n",
       "        [-2.5760214 ,  1.6123974 , -0.30458486, -4.237865  ],\n",
       "        [-2.4132226 ,  1.5682064 , -0.21297498, -3.8944771 ],\n",
       "        [-2.0381854 ,  1.4937346 , -1.0297415 , -3.6464343 ]],\n",
       "       dtype=float32),\n",
       " 'low_ys': array([[-1.1068422 ,  1.6963651 , -0.5735603 , -2.59298   ],\n",
       "        [-1.9189878 ,  1.7368743 ,  0.50924957, -3.2890606 ],\n",
       "        [-1.0813737 ,  1.6927959 , -0.11959975, -2.2212167 ],\n",
       "        ...,\n",
       "        [-2.54916   ,  1.6128898 , -0.25467768, -4.3898892 ],\n",
       "        [-2.3863654 ,  1.5706596 , -0.20527083, -4.026402  ],\n",
       "        [-2.037113  ,  1.4957746 , -0.97328293, -3.735905  ]],\n",
       "       dtype=float32),\n",
       " 'low_pred': array([[-1.1024573 ,  1.7007983 , -0.39156783, -2.3576071 ],\n",
       "        [-1.9236361 ,  1.7376287 ,  0.8233332 , -3.3941805 ],\n",
       "        [-1.1814524 ,  1.6987898 , -0.15710267, -2.339483  ],\n",
       "        ...,\n",
       "        [-2.5684164 ,  1.6144829 , -0.30458483, -4.250853  ],\n",
       "        [-2.4048674 ,  1.573455  , -0.21297498, -3.9009917 ],\n",
       "        [-2.04063   ,  1.4970658 , -1.0297415 , -3.6517885 ]],\n",
       "       dtype=float32),\n",
       " 'vars': tensor([[0.0272, 0.0033, 0.1861, 0.2397],\n",
       "         [0.2154, 0.0034, 0.0865, 0.2239],\n",
       "         [0.0239, 0.0082, 0.1187, 0.1916],\n",
       "         ...,\n",
       "         [0.0728, 0.0024, 0.0895, 0.2317],\n",
       "         [0.0390, 0.0015, 0.0567, 0.1192],\n",
       "         [0.0188, 0.0016, 0.1882, 0.2737]], device='cuda:0'),\n",
       " 'rhos': tensor([], size=(69, 0), dtype=torch.int32),\n",
       " 'low': [array([0.093647  , 0.03364303, 0.19445114, 0.35135224], dtype=float32)],\n",
       " 'epochexit': [499]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbf75f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 86/86 [01:14<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scatter: [0.0921 0.7799 0.723  0.4079]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc, preds , ys, var = test(test_loader)\n",
    "print(f'Test scatter: {np.round(test_acc.cpu().numpy(), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76895e1",
   "metadata": {},
   "source": [
    "## Model sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bee100e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaQ0lEQVR4nO3de5xU9X3/8ddnd1kIEcHIqtzqKiIWleuG0J83Eo1ysSF4BS+oSYrWmMb6sw9I0yT+Yms00dT4U0NpYtV4QatgvGBsm0RFDYblqohQ5LquVUgQRFDc3U//OAMZhpmd2d2ZOTPffT8fj3k455zvnPPhrPue757L95i7IyIi5a8i7gJERCQ/FOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLkEzs0Fm9pGZPZCYvtjMdia9dpmZm9moDJ9/PvH5ve1XZ2j3vcR6zijkv0ekNQp0Cd1dwKK9E+7+oLsftPcFXA2sA5a0so5rkj4zOHWhmQ0EzgPeyXPtIm2iQJdgmdkU4H3g1600uwy43zt2y/SdwAxgTwfWIdJhCnQJkpkdDHwf+L+ttDkSOBW4P8vqfmBmW83sZTMbm7KO84E97j6/YxWLdFxV3AWIFMiNwM/dfbOZZWozDVjg7utbWc8M4A2i3vcU4CkzG+7ub5nZQcBNwJl5rFuk3dRDl+CY2XDgDOCfszSdBtzXWgN3f9XdP3D3j939PuBlYEJi8f8DfpHlC0GkaNRDlxCNBWqBTYne+UFApZkNcfeRAGZ2EtAXeKyN63Zgb5f/dKC/mV2dmK4BHjWzW9z9lg79C0TawTR8roTGzLoDByfNup4o4P/a3bck2swGurn7tFbW0wv4HPAC0ARcCMwGRrr7ajM7FOiS9JFFwHXAs+6+M2//IJEcqYcuwXH3XcCuvdNmthP4KCnMuwEXAOemftbM/h44xd3HE4X1PwLHAc3Am8CX3X11Yjt/SPlsM7BNYS5xUQ9dRCQQOikqIhIIBbqISCAU6CIigVCgi4gEIrarXHr37u21tbVxbV5EpCwtXrx4q7vXpFsWW6DX1tZSX18f1+ZFRMqSmW3MtEyHXEREAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqEHXEinVjvzmbTzN9w8sciViHSceugiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBCJroJvZPWb2npm9nmG5mdkdZrbWzFaY2cj8lykiItnk0kO/FxjXyvLxwKDEazrw046XJSIibZU10N39ReCPrTSZBNzvkYVALzPrk68CRUQkN/k4ht4P2Jw03ZCYdwAzm25m9WZWv2XLljxsWkRE9spHoFuaeZ6uobvPdvc6d6+rqUn70GoREWmnfAR6AzAgabo/0JiH9YqISBvkI9CfBKYlrnYZA2x393fysF4REWmDrKMtmtnDwFigt5k1AN8DugC4+yxgPjABWAvsAq4oVLEiIpJZ1kB396lZljvw9bxVJCIi7aI7RUVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJRE6BbmbjzGy1ma01s5lplvc0s6fMbLmZrTSzK/JfqoiItCZroJtZJXAXMB4YAkw1syEpzb4OvOHuw4CxwG1mVp3nWkVEpBW59NBHA2vdfZ277wHmAJNS2jjQw8wMOAj4I9CU10pFRKRVuQR6P2Bz0nRDYl6yO4E/BxqB14BvuntLXioUEZGc5BLolmaep0yfBSwD+gLDgTvN7OADVmQ23czqzax+y5YtbSxVRERak0ugNwADkqb7E/XEk10BzPXIWmA9cFzqitx9trvXuXtdTU1Ne2sWEZE0cgn0RcAgMzsqcaJzCvBkSptNwOkAZnY4MBhYl89CRUSkdVXZGrh7k5ldAzwHVAL3uPtKM7sqsXwWcCNwr5m9RnSIZoa7by1g3SIikiJroAO4+3xgfsq8WUnvG4Ez81uaiIi0he4UFREJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQVXEXIFKKamc+k3b+hpsnFrkSkdzl1EM3s3FmttrM1prZzAxtxprZMjNbaWYv5LdMERHJJmsP3cwqgbuALwINwCIze9Ld30hq0wu4Gxjn7pvM7LAC1SsiIhnk0kMfDax193XuvgeYA0xKaXMRMNfdNwG4+3v5LVNERLLJJdD7AZuTphsS85IdCxxiZs+b2WIzm5ZuRWY23czqzax+y5Yt7atYRETSyiXQLc08T5muAkYBE4GzgO+Y2bEHfMh9trvXuXtdTU1Nm4sVEZHMcrnKpQEYkDTdH2hM02aru38IfGhmLwLDgDV5qVJERLLKpYe+CBhkZkeZWTUwBXgypc0vgVPMrMrMugOfA1blt1QREWlN1h66uzeZ2TXAc0AlcI+7rzSzqxLLZ7n7KjP7FbACaAF+5u6vF7JwERHZX043Frn7fGB+yrxZKdM/An6Uv9JERKQtdOu/iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoHIKdDNbJyZrTaztWY2s5V2nzWzZjM7L38liohILrIGuplVAncB44EhwFQzG5Kh3S3Ac/kuUkREssulhz4aWOvu69x9DzAHmJSm3TeAx4H38lifSJE5I20N1XwSdyEibZZLoPcDNidNNyTm7WNm/YDJwKzWVmRm082s3szqt2zZ0tZaRQqqhm38W5cfMrfrDTxQfROHsCPukkTaJJdAtzTzPGX6dmCGuze3tiJ3n+3ude5eV1NTk2OJIoV3VsXvea7rDMZUrOLepjMZZuv4ZfV3OMYa4i5NJGe5BHoDMCBpuj/QmNKmDphjZhuA84C7zezL+ShQpJB6sItbu8ziX6pvZ7Mfxtl7/okbmi7nwj3f4VO2h7nV3+PUiuVxlymSk1wCfREwyMyOMrNqYArwZHIDdz/K3WvdvRZ4DLja3Z/Id7EiebXhZZ7tOpPJFQv4SdNkzt1zA295dDRxmR/DpI9v5G2v4d+6/JBplTrXL6WvKlsDd28ys2uIrl6pBO5x95VmdlVieavHzUVK0qaFcO9EPvHDOO+TG1jqgw5o0khvztvzPW7vchff73IfA60Rms+Cyqy/NiKxMPfUw+HFUVdX5/X19bFsW4R7z4atazh+6018yKdabVpBCzOqHubKqmfgC/8Ap/5dkYoUOZCZLXb3unTLdKeodD4bXoINC+Dkv80a5gAtVPCDpov5z+aR8Lu74OOdRShSpO0U6NL5PH8zHHQEjLq8TR+7u2kS7N4Gi+8tSFkiHaVAl85l/YJ9vXO6ZO+dJ1vqg6D2FHjl/0PTxwUqUKT9FOjSuezrnV/Wvs+fej3s/B9Y9lB+6xLJAwW6dB7rX4SNL8Ep17W5d77PUadBv1Hw8u3Q3JTX8kQ6SoEunYP7n3rnI9vZOwcwg1Ouh20bYOXcvJUnkg8KdOkcNiyAjS8neufdOrauY8fBYUNgwW3Q0pKf+kTyQIEu4XOH3/4AevTpWO98r4oKOPk62PImrJ7f8fWJ5IkCXcK3/kXY9EoUwh3tne91/GQ45ChYcGv0hSFSAhToEjZ3eP4H0KMvjJyWv/VWVsHJ10LjUlj32/ytV6QDFOgStg0vwabf5efYeaphU6MvigU/zu96RdpJgS5hW3I/dO0JIy7J/7qrusL/+UZ0wnXTq/lfv0gbKdAlXB9th1VPwYnntv+682xGXQbdesGrGnRU4qdAl3CtnAdNu2F4AXrne1V/Gk48H958Bna/X7jtiORAgS7hWvYQ9B4M/UYWdjvDL4Lmj6MvEJEYKdAlTFv/Gza/CiMuju7uLKS+I6DmOI3vIrFToEuYlj0EVglDLyz8tsyiXnrD72Hr2sJvTyQDBbqEp6UZls+BY86AHkcUZ5tDLwSrgOXqpUt8FOgSnnW/hQ8ao15zsfQ4AgaeHn2RtDQXb7siSRToEp5lD8GnDoHB44u73eFTYcfb0VADIjHQ48slLLu3waqno+vDq7rmffW1M59JO3/DzRNh8MToJqZlD8HAz+d92yLZqIcuYXl9bnQJ4fCLi7/tLt2im5hWPQUf7Sj+9qXTUw9dwrLsQTjseOgzbN+sTL3qghh2EdTfA288kd/BwERyoB66hOO9N+HtxdHJ0EJfe55J/zo4dBAsezie7UunpkCXcCx7ECqqinPteSZm0cnRTa/AH9fFV4d0Sgp0CUNzE6x4BAadCQfVxFvL0CmARZcwihSRAl3C8NavYee78ZwMTdWzHxw9NjrsomeOShEp0CUMSx+A7r2jHnopGH4xbN8EG1+KuxLpRBToUv4+3Aqrn4VhU6CqOu5qIsdNhK4Ha8AuKSoFupS/FY9Cyyelcbhlr+rucMK5sPKJ6EEbIkWQU6Cb2TgzW21ma81sZprlF5vZisTrFTMblm49InnnDkt/Af1GweFD4q5mfyMvjR6w8dpjcVcinUTWQDezSuAuYDwwBJhqZqm/OeuB09x9KHAjMDvfhYqk1bgE3nujMM8M7ai+I+HwE6IvHJEiyKWHPhpY6+7r3H0PMAeYlNzA3V9x922JyYVA//yWKZLB0geg6lPR4Y1SYwYjLoXGpfDOirirkU4gl0DvB2xOmm5IzMvkq8CzHSlKJCd7dkWHM4ZMgm49464mvaEXQGVX9dKlKHIJ9HT3UHvahmafJwr0GRmWTzezejOr37JlS+5ViqTz5tPw8Y7SPNyyV/fPwJ+fHd309MnuuKuRwOUS6A3AgKTp/kBjaiMzGwr8DJjk7n9ItyJ3n+3ude5eV1MT8918Uv6W/gIOqYUjT4q7ktaNnBZd6bLq6bgrkcDlEuiLgEFmdpSZVQNTgCeTG5jZnwFzgUvdfU3+yxRJsW1D9CCJ4ZdARYlffVt7KvQ6EpbeH3clErisvwnu3gRcAzwHrAIedfeVZnaVmV2VaPZd4FDgbjNbZmb1BatYBGDpg0BiIKxSV1ERnRxd/6IG7JKCyqlr4+7z3f1Ydx/o7v+UmDfL3Wcl3n/N3Q9x9+GJV10hi5ZOrqU58VSgL0DPMrmgavhF0UOklz4YdyUSsBL/W1UkjXXPw46G6MadctGzHxxzRjTEb3NT3NVIoBToUn6WPpB4CPSEuCtpm5HT4IN3opEhRQpAgS7lZdcfo8sVh15YkIdAF9Sx4+DTNbBEJ0elMBToUl5WPALNe0r72vNMKrvAsKmw5lfwwbtxVyMBUqBL+WjaA6/cCQPGwBEnxl1N+4y4FFqaYLmG1ZX8q4q7AJGcrXgkOhn6l7enXVw785ni1tMeNcfCkSfD7/8VxlxdfoeNpKSphy7loaUZXvox9BkWXS1Szk65Dna8HZ3cFckjBbqUh5XzoptyTrk+GsWwnA38AvQfDS/9c3QYSSRPdMhFSl9LCyy4DWqOg+POjruatDId7tlw88QDZ5rB2BnwwLnRdel1VxS4Ouks1EOX0rfm2eghFidfV/rjtuRq4OnQry76olIvXfIkkN8OCZY7vHhrNKpiKT7Eor3MYOxM2L5ZV7xI3ijQpbS99ZvoMXMnXQuVgR0hPOaM6DF1C26D5k/irkYCoECX0rbgNujRNxrcKjR7e+nvb4LlD8ddjQRAgS6la+PvYOPLcNLfhHu99qAzoe+I6LCSeunSQQp0KV0LboXuvWHkZXFXUjhmcNpMeH8jLJ8TdzVS5hToUpreXgJr/wv+4mqo7h53NYV17FnQZ3j0BaZeunSAAl1KT3MT/Opb0K0nfPZrcVdTeGZw2ozosXorHo27GiljCnQpPQtug80LYcKtUah3BoPHR8Ma/OZG+HBr3NVImQrsOjApe5sWwgs3R+OdD70g7mo6LOc7SM3gS3fCz86AuX8FFz8ezk1UUjQKdCkdH22Hx/8Keg6IeucZlMWoiu3RZyiMvwWevjb6K+W0v4u7Iikz6gJIaXCHp/82GoXw3J9Dt4Pjrigeoy6HE8+H52+C9S/GXY2UGQW6lIblc+D1x+Hz34IBn427mviYwdm3w2cGwuNfg53vxV2RlBEFusTvD2/B/OvhyJOiAbg6u64HwQX3wUc74PGvRmPBi+RAgS7xav4k6olWVME5s6GiMu6KSsPhx8OEH0WHXV74YdzVSJlQoEt8mpuinnnjEvjSHdCzf9wVlZYRl0QPlX7hlmiQMpEsFOgSjw+3wgOTYfG90UiKQybFXVHpMYOJt0HNYHhkWnSOQaQVumxRiq9xGTxySXTC78s/zTiSYrCXJ7ZF9afhksfh36+Ax74CG16Gs26CLt3irkxKkAJdimv5HHjqm9GgW199LhppsBNq0yPrevaHK+bDr78Pr9wBDb+H8++DQwcWuEopNzrkIsXR/Ak8OwPmXQn9PwtXvtBpw7xdKrvAmTfCRY/C9gb4l1PhtcfirkpKjLl7LBuuq6vz+vr6WLYtRbT7fXjt36H+nui5oGO+Dl/8/n5PH9Khlez267lvb4gOv2x+NTppOnp69OVoFl+BUjRmttjd69It0yEXyT932PQ7WHwfvPEENH0ERwyF8++F4yfHXV3569kfLn8GfvOPsPDu6GlHvQfDsAujMXB0tVCnlVMP3czGAT8BKoGfufvNKcstsXwCsAu43N2XtLZO9dAD0twE29ZHPfB3V8LKebB1DVT3gBPPg1GXQd8R6ol3QNpj6wC7t8HKJ2DFI9GXKAa1J8MJ58DhJ8Chx0D3zxSzVCmw1nroWQPdzCqBNcAXgQZgETDV3d9IajMB+AZRoH8O+Im7f6619SrQS4w7tDRB857oeHfy+48/iAbO2vd6H3a/z7zfLGCwNTDQGulqf3oww+KWQcxp/jxPN49hN7oao1gG2LtMrniZcyoXUFvx7p8WdO8NvQdFr88cDd16RWPldO2Z+G+P6FVZHd3gVVEVHbOv6BLd6KVDOSWlo4dcRgNr3X1dYmVzgEnAG0ltJgH3e/TtsNDMeplZH3d/p4O1H2jVUzDvqryvtmxl+ELetadp33vD93tvgNFCBY7hVFr7zqOMrjiUNS39WdByAmtaBrDG+7PW+yrEY7LZD+eO5nO4o3kyR9q7DLRGjrZ3GLijkYE7Gzl64xP0th3tWLOBVSSCPeX9via2f/u0q9EXwz5jroYvfDvvq80l0PsBm5OmG4h64dna9AP2C3Qzmw5MT0zuNLPVbaq28HoD5fR0gZjr3QGsz7VxOe3bcqoV0tS7ESjRsRrLad8WsNZ/SLza5chMC3IJ9HRfq6ldulza4O6zgdk5bDMWZlaf6U+ZUlRO9arWwimnelVrYeVyHXoDMCBpuj/Q2I42IiJSQLkE+iJgkJkdZWbVwBTgyZQ2TwLTLDIG2F6Q4+ciIpJR1kMu7t5kZtcAzxFdtniPu680s6sSy2cB84mucFlLdNniFYUruaBK9nBQBuVUr2otnHKqV7UWUGx3ioqISH5pLBcRkUAo0EVEAtGpA93MHjGzZYnXBjNblqHdBjN7LdEutttbzewGM3s7qeYJGdqNM7PVZrbWzGYWu85EDT8yszfNbIWZzTOzXhnaxbZvs+2nxEn+OxLLV5jZyGLWl1THADP7rZmtMrOVZvbNNG3Gmtn2pP83vhtHrUn1tPpzLaF9Ozhpny0zsx1mdm1Km5Lat61yd72i8wi3Ad/NsGwD0LsEarwBuD5Lm0rgLeBooBpYDgyJodYzgarE+1uAW0pp3+ayn4hO9D9LdJ/FGODVmH7ufYCRifc9iIbiSK11LPB0HPW15+daKvs2zf8T/wMcWcr7trVXp+6h75UYXOwC4OG4a8mDfUM1uPseYO9QDUXl7v/h7nvHH1hIdG9CKcllP+0b0sLdFwK9zKxPsQt193c8Mdidu38ArCK6E7uclcS+TXE68Ja7b4y5jnZToEdOAd519//OsNyB/zCzxYnhC+J0TeJP1HvM7JA0yzMNwxCnrxD1xtKJa9/msp9Kbl+aWS0wAng1zeK/MLPlZvasmR1f3MoOkO3nWnL7lugem0ydulLatxkFPx66mf0XcESaRd92918m3k+l9d75Se7eaGaHAf9pZm+6e0GGymitXuCnwI1Evyw3Eh0m+krqKtJ8tiDXpuayb83s20AT8GCG1RRt36bI25AWxWJmBwGPA9e6e+ooW0uIDhXsTJxbeQIYVOQSk2X7uZbavq0GvgR8K83iUtu3GQUf6O5+RmvLzawKOAcY1co6GhP/fc/M5hH9uV6Q0MlW715m9q/A02kWFW0Yhhz27WXA2cDpnjgYmWYdRdu3KcpqSAsz60IU5g+6+9zU5ckB7+7zzexuM+vt7rEMhJXDz7Vk9m3CeGCJu7+buqDU9m1rdMgFzgDedPeGdAvN7NNm1mPve6KTfa8Xsb7kWpKPMU7OUEcuQzUUnEUPRZkBfMndd2VoE+e+LZshLRLneH4OrHL3H2doc0SiHWY2muh3+w/Fq3K/WnL5uZbEvk2S8a/0Utq32QTfQ8/BAcfNzKwv0ZOZJgCHA/MSP88q4CF3/1XRq4z80MyGE/1pugG4Evav1zMM1RBDrXcCXYn+3AZY6O5Xlcq+zbSfrDSHtDgJuBR4zf50ae3fA38G+2o9D/hrM2sCdgNTMv1VVARpf64lum8xs+5ED/C5Mmlecq2ltG9bpVv/RUQCoUMuIiKBUKCLiARCgS4iEggFuohIIBToIiKBUKCLiARCgS4iEoj/Be+Mu4Oyh6SEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX5UlEQVR4nO3de5hU1Z3u8e9LA5p4Q6V1FIiQBM3oeDna4GUSxTvonENMoiPxxPsQo3jmZC5HTLxMxsx5zMXRyUQlRAkmGh3HS0TF+ziCQSNtNAoqCYJIi4ZWVERU6O7f/LELp227u6q7d1V1rX4/z1MPtfdetfev6yneXr1q77UVEZiZWe0bVO0CzMwsHw50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQLfkSNpM0rWSVkh6R9JTkiYVtp0kaV27x3pJIWm/LvY1TVKjpA8kze6w7QBJD0haI6lZ0r9L2qkCP6JZpxzolqLBwErgEGAb4ELgZkmjI+KGiNhy0wM4G1gG/LaLfa0CvgvM6mTbtsBMYDSwC/AO8LM8fxCznpCvFLWBQNIzwHci4tYO6x8G/jMivlPk9d8FRkbEqd202Rd4JCK2yqFksx5zD92SJ2lHYFdgcYf1uwAHAz/P6VAHdzyGWSUNrnYBZuUkaQhwA3BdRLzQYfPJwPyIWJ7DcfYCLgIm93VfZr3lHrolS9Ig4BfABmBaJ01OBq7L4TifBe4B/joi5vd1f2a95R66JUmSgGuBHYFjImJjh+1/DuwM3NLH4+wCPAhcEhG/6Mu+zPrKgW6puhr4U+CIiHivk+2nALdGxDvd7UTSYLL/J3VAnaTNgZaIaJE0AvgP4MqImJFv+WY95yEXS06h1/x1YB/gtXbnnJ9U2L45cAKdDLdI+pake9qtugB4D5gO/O/C8wsK284EPg1c3P7c9jL9WGZF+bRFM7NEuIduZpYIB7qZWSIc6GZmiXCgm5klomqnLQ4fPjxGjx5drcObmdWkJ5988vWIqO9sW9UCffTo0TQ2Nlbr8GZmNUnSiq62ecjFzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRvmORJWP09Ls7Xf/SpcdWuBKz6nAP3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEUUDXdIsSaslLSrSbpykVklfya88MzMrVSk99NnAxO4aSKoDvgfcl0NNZmbWC0UDPSLmAWuKNDsXuBVYnUdRZmbWc30eQ5c0AjgOmFFC26mSGiU1Njc39/XQZmbWTh5fil4BnBcRrcUaRsTMiGiIiIb6+vocDm1mZpvkMX1uA3CTJIDhwDGSWiLiVzns28zMStTnQI+IMZueS5oN3OUwNzOrvKKBLulGYAIwXFITcDEwBCAiio6bm5lZZRQN9IiYUurOIuLUPlVjZma95itFzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBFFA13SLEmrJS3qYvtJkp4pPBZI2jv/Ms3MrJhSeuizgYndbF8OHBIRewGXADNzqMvMzHpocLEGETFP0uhuti9ot/g4MDKHuszMrIfyHkM/A7inq42SpkpqlNTY3Nyc86HNzAa23AJd0qFkgX5eV20iYmZENEREQ319fV6HNjMzShhyKYWkvYBrgEkR8UYe+zQzs57pcw9d0qeA24CvRcTv+16SmZn1RtEeuqQbgQnAcElNwMXAEICImAFcBGwPXCUJoCUiGspVsJmZda6Us1ymFNl+JnBmbhWZmVmv+EpRM7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBJRNNAlzZK0WtKiLrZL0o8kLZX0jKR98y/TzMyKKaWHPhuY2M32ScDYwmMqcHXfyzIzs54qGugRMQ9Y002TycDPI/M4MEzSTnkVaGZmpcljDH0EsLLdclNh3cdImiqpUVJjc3NzDoc2M7NN8gh0dbIuOmsYETMjoiEiGurr63M4tJmZbZJHoDcBo9otjwRW5bBfMzPrgTwCfQ5wcuFslwOAtyPi1Rz2a2ZmPTC4WANJNwITgOGSmoCLgSEAETEDmAscAywF1gOnlatYMzPrWtFAj4gpRbYHcE5uFZmZWa/4SlEzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLREmBLmmipCWSlkqa3sn2bSTdKel3khZL8o2izcwqrGigS6oDrgQmAbsDUyTt3qHZOcBzEbE3MAG4TNLQnGs1M7NulNJDHw8sjYhlEbEBuAmY3KFNAFtJErAlsAZoybVSMzPrVimBPgJY2W65qbCuvR8DfwqsAp4F/joi2jruSNJUSY2SGpubm3tZspmZdaaUQFcn66LD8tHA08DOwD7AjyVt/bEXRcyMiIaIaKivr+9hqWZm1p1SAr0JGNVueSRZT7y904DbIrMUWA58Lp8SzcysFKUE+kJgrKQxhS86TwTmdGjzMnA4gKQdgd2AZXkWamZm3RtcrEFEtEiaBtwH1AGzImKxpLMK22cAlwCzJT1LNkRzXkS8Xsa6zcysg6KBDhARc4G5HdbNaPd8FXBUvqWZmVlP+EpRM7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQDczS0RJgS5poqQlkpZKmt5FmwmSnpa0WNIj+ZZpZmbFFL1JtKQ64ErgSKAJWChpTkQ8167NMOAqYGJEvCxphzLVa2ZmXSilhz4eWBoRyyJiA3ATMLlDm68Ct0XEywARsTrfMs3MrJhSAn0EsLLdclNhXXu7AttK+k9JT0o6ubMdSZoqqVFSY3Nzc+8qNjOzTpUS6OpkXXRYHgzsBxwLHA1cKGnXj70oYmZENEREQ319fY+LNTOzrhUdQyfrkY9qtzwSWNVJm9cj4l3gXUnzgL2B3+dSpZmZFVVKD30hMFbSGElDgROBOR3a3AF8QdJgSZ8E9geez7dUMzPrTtEeekS0SJoG3AfUAbMiYrGkswrbZ0TE85LuBZ4B2oBrImJROQs3M7OPKmXIhYiYC8ztsG5Gh+UfAD/IrzQzM+sJXylqZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSJKCnRJEyUtkbRU0vRu2o2T1CrpK/mVaGZmpSga6JLqgCuBScDuwBRJu3fR7ntkN5M2M7MKK+Um0eOBpRGxDEDSTcBk4LkO7c4FbgXG5VqhWR/tOv1XbGBIp9teuvTYCldjVj6lDLmMAFa2W24qrPuQpBHAccCM7nYkaaqkRkmNzc3NPa3VrEdG6Y9cPeRyFm12Ol+pe6Ta5ZiVXSk9dHWyLjosXwGcFxGtUmfNCy+KmAnMBGhoaOi4D7NcbMl6pg2+g9Pq7qGFOn4fo/jhkJ+wDe9ybesx1S7PrGxKCfQmYFS75ZHAqg5tGoCbCmE+HDhGUktE/CqPIs1KMYg2jq97hL8b/G/Uay23tB7M9zf+JW+xJZcPuZILh1zPMK3jspbj6byfYlbbSgn0hcBYSWOAV4ATga+2bxARYzY9lzQbuMthbhW1Zhl3Dv02ewxawcK2XTl9w//j2fj0h5vP3fh/WBvXcu7gX7Et73BRy2m0+axdS0zRQI+IFknTyM5eqQNmRcRiSWcVtnc7bm5WEXf/LaPUzLQN53JX2wF07IG3MYjzW87kLbbkG4PvZBu9y99sPLs6tZqVSSk9dCJiLjC3w7pOgzwiTu17WWY9sPRBePE/uKLla9zVdmA3DcX3WqbwZmzJt4bcyNash41Hw5DNK1aqWTn5b06rbW2tcP+FsO0YftF6ZEkvmdn6P5m+8UwOqXsGnphZ5gLNKseBbrXtqeth9XNwxD+wsbQ/OAG4qfUw5rXuCb/+F9jwbhkLNKscB7rVrg/WwcP/BKP2h90n9/jlV7R8Gda/DguvKUNxZpXnQLfateBfYd0f4ah/gm6uf+jKb2NX+MxhWS/9g3VlKNCsshzoVpvWvgoLfgR7HAej+jDbxITzYf0b7qVbEhzoVpse/i60tcDhF/dtP6PGw2cOz345uJduNc6BbrXntUXw1A0wfipsN6Z4+2I+7KX/tO/7MqsiB7rVlgi4/wLYfBs4+O/y2eeocfDZI+DXP4IP3slnn2ZV4EC32vLiQ7DsYTjkPPjEtvntd8L58N4aeMK9dKtdDnSrLfMvh21Gwbgz893vyAb47JGFsXT30q02OdCtdqx6ClY8CvufBYOH5r//CefDe2/66lGrWQ50qx2PXQVDt4R9v1ae/Y/cD8YenZ3f/v7a8hzDrIwc6FYb1q6CxbfBvidnX4iWy4Tzsl76kz8r3zHMysSBbrXhiZkQbbD/18t7nBH7wegvwG9+Aq0by3sss5w50K3/2/AuNP4MPvcXsO3o8h/vwGmw9hV47o7yH8ssRw506/+e/iW8/xYceE5ljjf2KNh+LDz24+y8d7Ma4UC3/q2tDR6/OhsKGbV/ZY45aBAceHbhrJoFlTmmWQ4c6Na//eE+WPMiHHB2r2ZU7LW9ToRPbAePXVm5Y5r1kQPd+rfHroStR/ZqvvM+GfpJGHcGLJkLb7xY2WOb9VJJgS5poqQlkpZKmt7J9pMkPVN4LJC0d/6l2oDz6u/gpfnZmS11Qyp//HF/lR338asrf2yzXiga6JLqgCuBScDuwBRJu3dothw4JCL2Ai4BfKmd9d1jV8GQLbJzz6thqx1hzxPg6Rtg/Zrq1GDWA6X00McDSyNiWURsAG4CPvL3b0QsiIg3C4uPAyPzLdMGnLWvwqJbs6tCPzGsenUceDZsXO8LjawmlBLoI4CV7ZabCuu6cgZwT2cbJE2V1Cipsbm5ufQqbeB54ifZDSzKfSFRMTvuAZ8+FH4zE1o2VLcWsyJKCfTOTi3o9ORcSYeSBfp5nW2PiJkR0RARDfX19aVXaQPLu29kAbrHF2G7T1e7GjhoGqx7LZt6wKwfKyXQm4BR7ZZHAqs6NpK0F3ANMDki3sinPBuQfn0FtLyXzX7YH3zmcKj/nC80sn6vlEBfCIyVNEbSUOBEYE77BpI+BdwGfC0ifp9/mTZgrFud3WRiz+OhfrdqV5ORsqtUX3sWlj9S7WrMulQ00COiBZgG3Ac8D9wcEYslnSXprEKzi4DtgaskPS2psWwVW9oevRxaN2R3JOpP9jwBttoZHrrEvXTrtwaX0igi5gJzO6yb0e75mUDOt5CxAWftq7DwWth7Cmz/mWpX81FDNofDvg13nAOLb4c/+1K1KzL7GF8pav3H/MsgWvO7+XPe9p4CO+wBD30HWj6odjVmH1NSD92s7N5aCb+9DvY5CbYb023T0dPvrlBRHQyqg6P+Ea7/cvaXxIFnV6cOsy64h279w/wfZmPTB/99tSvp3mePyM5Ln/d9eO+taldj9hEOdKu+Ncvhqethv1Ng2Kji7avtyH/Mwnz+ZdWuxOwjPORi1Tfvh6A6+MLfVvzQXQ3fvHTpsV2/aKe9YO8Ts9vUjf8rGPapMlVn1jPuoVt1vfEi/O5GaDgdtt652tWU7rALsvPTH7qk2pWYfciBbtUTAfdfCHVD4fPfrHY1PbPNSDjgG/Dszdmdjcz6AQe6Vc9vZsCSu+HQb2VT1daaz38TPrl99kvJFxtZP+BAt+pYuRDuvwB2OxYOOrfa1fTO5ttkV7S+ND+7s5FZlTnQrfLWr4F/PxW2HgFfvKqy9wrN236nZRcb3f4NWP18tauxAc6BbpXV1ga3TYV3V8MJ11X35hV5GDwUvvpvMOQTcMPx8M5r1a7IBjAHulXWo5fB0gdg4qWw8/+odjX5GDYKTro5+8vjlyfAB+uqXZENUA50q5zl8+Dh/59NjdtwerWryddOe8Pxs+G1RXDLadDaUu2KbADyhUVWGe+8BrecAduPhb+4oqRx86rN2dJbux4Fx/4Q7vom3PP3cOw/1/b3A1ZzHOhWfs1L4JbTYcM6OOVO2GzLaldUPg2nw5srsrsuDdsFPv9/q12RDSAOdCufCHhiJjxwEQzdAv7yF7DD56pdVUl6NSXAJodfDG+vhAcvhsGbwfip2UyNZmXmQLfyWPtqdjOIFx+CsUfB//pxbV481BuDBsHkq+D9t+He6fD0L2HS92GXA6tdmSXOX4pa/p6bA1cfCCsWZOPIX7154IT5JkM2h5NugS9fC+vfgJ9NzL5DePuValdmCXMP3fLx/tuw9EFYdBu8cFd2SuKXfgrDxxZ9ac19+VkqCfb8Cuw2CR69Ahb8KLui9PN/AwdNy85dN8uRooQ5KCRNBP4FqAOuiYhLO2xXYfsxwHrg1Ij4bXf7bGhoiMZG30u6pr31Miy5N5uP5aVHoa0lm9tk3JnZjSrqhpS0mxQCvaSx9TdXZNMdPD8H6jaDkeOyYZhdDoKR49P+sthyI+nJiGjobFvRHrqkOuBK4EigCVgoaU5EPNeu2SRgbOGxP3B14V+rBRHQ1gqtH2T3ymx5Hza+V3j+HqxbDWtXtXu8kn3pt2ZZ9vrhu8KB58Bux2Qh1cUXgCkEd59su0v2xfCKx7K/YlYsgPn/DPN+kM0Hv9Pe8Cd/Bp8cDlvUwxbDs1+QWwzP5o2pG1p4DPnv5/6y1dopZchlPLA0IpYBSLoJmAy0D/TJwM8j6+4/LmmYpJ0i4tXcK37+Trj9rNx3W7O6/AsrumgTEG0ffZSoJQbxR7bltdiO12I4T7cdwINt+7G8aafsV/1DbwD39uKHqH09/2V1EHAQW/Ae+w76A+MHvcD4phfY/+17szH3aC1xP8qGdjSo8HxQ4dx3dXMOfBfrfc585RxwNhz27dx3W0qgjwBWtltu4uO9787ajAA+EuiSpgJTC4vrJC3p5rjDgddLqG+gq/D79BawvPD8wcodtm/69WfpOeD6ahfRz9+jfiLH9+iCwqNXdulqQymB3tmv7Y7dwlLaEBEzgZklHBNJjV2NE9l/8/tUnN+j4vweFVcL71Eppy02Ae3v3DsSWNWLNmZmVkalBPpCYKykMZKGAicCczq0mQOcrMwBwNtlGT83M7MuFR1yiYgWSdOA+8hOW5wVEYslnVXYPgOYS3bK4lKy0xZPy6G2koZmzO9TCfweFef3qLh+/x6VdB66mZn1f77038wsEQ50M7NE9LtAl3S8pMWS2iQ1dNh2vqSlkpZIOrpaNfYnkv5B0iuSni48jql2Tf2FpImFz8pSSdOrXU9/JOklSc8WPjuei6NA0ixJqyUtarduO0kPSPpD4d9tq1ljZ/pdoAOLgC8B89qvlLQ72Rk2ewATgasK0xIYXB4R+xQec6tdTH/QbsqKScDuwJTCZ8g+7tDCZ6dfn2NdYbPJcqa96cBDETEWeKiw3K/0u0CPiOcjorMrSCcDN0XEBxGxnOyMmvGVrc5qyIdTVkTEBmDTlBVmRUXEPGBNh9WTgesKz68DvljJmkrR7wK9G11NL2AwTdIzhT8T+92fgVXiz0tpArhf0pOFqTmsaztuur6m8O8OVa7nY6oyH7qkB4E/6WTTtyPijq5e1sm6AXHOZXfvF9nMlpeQvReXAJcBp1euun5rwH5eeujPI2KVpB2AByS9UOidWg2qSqBHxBG9eNmAnV6g1PdL0k+Bu8pcTq0YsJ+XnoiIVYV/V0u6nWyoyoHeuT9umkVW0k7A6moX1FEtDbnMAU6UtJmkMWRzrz9R5ZqqrvDB2uQ4si+VrbQpKwY0SVtI2mrTc+Ao/PnpzhzglMLzU4CuRhOqpt/dgk7SccC/AvXA3ZKejoijC9MN3Ew222gLcE5EyZNGp+z7kvYhG054Cfh6VavpJ7qasqLKZfU3OwK3ZzccYzDwy4gYmBPadyDpRmACMFxSE3AxcClws6QzgJeB46tXYed86b+ZWSJqacjFzMy64UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBH/BbcwZHLhULqQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# labels = ['node']\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "node = [p.detach().numpy().flatten() for p in model.node_enc.parameters()]\n",
    "nodep = np.hstack(node)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "vals, bine, fig = ax.hist(nodep, bins=50, density=1)\n",
    "ax.plot(bine, norm.pdf(bine,0,1))\n",
    "ax.set_title(f'{sum(abs(nodep))/len(nodep)*100:.2f}')\n",
    "\n",
    "edge = [p.detach().numpy().flatten() for p in model.edge_enc.parameters()]\n",
    "edgep = np.hstack(edge)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "vals, bine, fig = ax.hist(edgep, bins=50, density=1)\n",
    "ax.plot(bine, norm.pdf(bine,0,1))\n",
    "ax.set_title(f'{sum(abs(edgep))/len(edgep)*100:.2f}')\n",
    "\n",
    "for conv in model.convs:\n",
    "    \n",
    "    edge = [p.detach().numpy().flatten() for p in conv.edge_model.parameters()]\n",
    "    edgep = np.hstack(edge)\n",
    "\n",
    "    node1 = [p.detach().numpy().flatten() for p in conv.node_model.node_mlp_1.parameters()]\n",
    "    node1p = np.hstack(node1)\n",
    "\n",
    "    node2 = [p.detach().numpy().flatten() for p in conv.node_model.node_mlp_2.parameters()]\n",
    "    node2p = np.hstack(node2)\n",
    "    \n",
    "    fig, ax =plt.subplots(1, 3, figsize=(17,4))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    vals, bine, fig = ax[0].hist(node1p, bins=50, density=1)\n",
    "    ax[0].plot(bine, norm.pdf(bine,0,1))\n",
    "    ax[0].set_title(f'{sum(abs(node1p))/len(node1p)*100:.2f}')\n",
    "    \n",
    "    vals, bine, fig = ax[1].hist(node2p, bins=50, density=1)\n",
    "    ax[1].plot(bine, norm.pdf(bine,0,1))\n",
    "    ax[1].set_title(f'{sum(abs(node2p))/len(node2p)*100:.2f}')\n",
    "    \n",
    "    vals, bine, fig = ax[2].hist(edgep, bins=50, density=1)\n",
    "    ax[2].plot(bine, norm.pdf(bine,0,1))\n",
    "    ax[2].set_title(f'{sum(abs(edgep))/len(edgep)*100:.2f}')\n",
    "# model.convs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37bd388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (7): Linear(in_features=64, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "895c61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('node encoder', sum(layer.abs().sum() for layer in model.node_enc.parameters())/\\\n",
    "#       sum(layer.numel() for layer in model.node_enc.parameters())*100)\n",
    "\n",
    "node = [p.detach().numpy().flatten() for p in model.node_enc.parameters()]\n",
    "nodep = np.hstack(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b34a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT9UlEQVR4nO3dcayd9X3f8fendqA0DQqMC3Vtp6aSlQ2QQsKV5wptykZa3FDFrBqTI61YLZJTRKdE2rSZVuo6VZbIpkUr22DykhSjJWFeW4qVlCye16j/EMiFkjgGPJxA4M6u7TK1IctEZ++7P86P5PT63HvPNdfnXvf3fkmPnud8n9/v8e88Bz73ub/znHNTVUiS+vBDKz0ASdLkGPqS1BFDX5I6YuhLUkcMfUnqyNqVHsBirrrqqtq0adNKD0OSLipPP/30n1bV1Nz6qg/9TZs2MTMzs9LDkKSLSpJvj6o7vSNJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1Z9Z/IlVbapt1fGFl/+b7bJjwS6a3zSl+SOmLoS1JHDH1J6siioZ/k3UmeHVq+k+RjSa5McjDJi219xVCfe5McS3I0ya1D9ZuSHG777k+SC/XEJEnnWjT0q+poVd1YVTcCNwHfAx4FdgOHqmozcKg9Jsl1wA7gemAb8ECSNe1wDwK7gM1t2basz0aStKClTu/cAnyzqr4NbAf2tfo+4Pa2vR14pKreqKqXgGPAliTrgMur6omqKuDhoT6SpAlYaujvAD7Xtq+pqhMAbX11q68HXh3qM9tq69v23Po5kuxKMpNk5vTp00scoiRpPmOHfpJLgA8B/2WxpiNqtUD93GLV3qqarqrpqalz/tqXJOk8LeVK/2eBZ6rqZHt8sk3Z0NanWn0W2DjUbwNwvNU3jKhLkiZkKaH/YX4wtQNwANjZtncCjw3VdyS5NMm1DN6wfapNAb2eZGu7a+fOoT6SpAkY62sYkvwI8NPAR4bK9wH7k9wFvALcAVBVR5LsB54DzgD3VNXZ1udu4CHgMuDxtkiSJmSs0K+q7wF/bU7tNQZ384xqvwfYM6I+A9yw9GFKkpaDn8iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjJW6Cd5Z5LfSfJCkueT/FSSK5McTPJiW18x1P7eJMeSHE1y61D9piSH2777k+RCPClJ0mjjXun/FvDFqvrrwHuA54HdwKGq2gwcao9Jch2wA7ge2AY8kGRNO86DwC5gc1u2LdPzkCSNYdHQT3I58LeBTwFU1V9U1Z8B24F9rdk+4Pa2vR14pKreqKqXgGPAliTrgMur6omqKuDhoT6SpAkY50r/J4HTwG8n+eMkn0zyduCaqjoB0NZXt/brgVeH+s+22vq2Pbd+jiS7kswkmTl9+vSSnpAkaX7jhP5a4H3Ag1X1XuB/06Zy5jFqnr4WqJ9brNpbVdNVNT01NTXGECVJ4xgn9GeB2ap6sj3+HQY/BE62KRva+tRQ+41D/TcAx1t9w4i6JGlCFg39qvoT4NUk726lW4DngAPAzlbbCTzWtg8AO5JcmuRaBm/YPtWmgF5PsrXdtXPnUB9J0gSsHbPdPwI+k+QS4FvALzL4gbE/yV3AK8AdAFV1JMl+Bj8YzgD3VNXZdpy7gYeAy4DH2yJJmpCxQr+qngWmR+y6ZZ72e4A9I+ozwA1LGJ8kaRn5iVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkrNBP8nKSw0meTTLTalcmOZjkxba+Yqj9vUmOJTma5Nah+k3tOMeS3J8ky/+UJEnzWcqV/t+pqhuraro93g0cqqrNwKH2mCTXATuA64FtwANJ1rQ+DwK7gM1t2fbWn4IkaVxvZXpnO7Cvbe8Dbh+qP1JVb1TVS8AxYEuSdcDlVfVEVRXw8FAfSdIEjBv6BXwpydNJdrXaNVV1AqCtr2719cCrQ31nW219255bP0eSXUlmksycPn16zCFKkhazdsx2N1fV8SRXAweTvLBA21Hz9LVA/dxi1V5gL8D09PTINpKkpRvrSr+qjrf1KeBRYAtwsk3Z0NanWvNZYONQ9w3A8VbfMKIuSZqQRUM/yduTvOPNbeBngG8AB4CdrdlO4LG2fQDYkeTSJNcyeMP2qTYF9HqSre2unTuH+kiSJmCc6Z1rgEfb3ZVrgc9W1ReTfBXYn+Qu4BXgDoCqOpJkP/AccAa4p6rOtmPdDTwEXAY83hZJ0oQsGvpV9S3gPSPqrwG3zNNnD7BnRH0GuGHpw5QkLQc/kStJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHxv0buZLm2LT7CyPrL99324RHIo3PK31J6oihL0kdMfQlqSNjh36SNUn+OMnn2+MrkxxM8mJbXzHU9t4kx5IcTXLrUP2mJIfbvvvT/tq6JGkylnKl/1Hg+aHHu4FDVbUZONQek+Q6YAdwPbANeCDJmtbnQWAXsLkt297S6CVJSzJW6CfZANwGfHKovB3Y17b3AbcP1R+pqjeq6iXgGLAlyTrg8qp6oqoKeHiojyRpAsa90v83wD8F/t9Q7ZqqOgHQ1le3+nrg1aF2s622vm3PrZ8jya4kM0lmTp8+PeYQJUmLWTT0k/wccKqqnh7zmKPm6WuB+rnFqr1VNV1V01NTU2P+s5KkxYzz4aybgQ8l+SDww8DlSf4TcDLJuqo60aZuTrX2s8DGof4bgOOtvmFEXZI0IYte6VfVvVW1oao2MXiD9r9X1T8EDgA7W7OdwGNt+wCwI8mlSa5l8IbtU20K6PUkW9tdO3cO9ZEkTcBb+RqG+4D9Se4CXgHuAKiqI0n2A88BZ4B7qups63M38BBwGfB4WyRJE7Kk0K+qLwNfbtuvAbfM024PsGdEfQa4YamDlCQtDz+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjiwa+kl+OMlTSb6W5EiSf9HqVyY5mOTFtr5iqM+9SY4lOZrk1qH6TUkOt333J8mFeVqSpFHGudJ/A/i7VfUe4EZgW5KtwG7gUFVtBg61xyS5DtgBXA9sAx5IsqYd60FgF7C5LduW76lIkhazaOjXwHfbw7e1pYDtwL5W3wfc3ra3A49U1RtV9RJwDNiSZB1weVU9UVUFPDzUR5I0AWPN6SdZk+RZ4BRwsKqeBK6pqhMAbX11a74eeHWo+2yrrW/bc+uj/r1dSWaSzJw+fXoJT0eStJCxQr+qzlbVjcAGBlftNyzQfNQ8fS1QH/Xv7a2q6aqanpqaGmeIkqQxLOnunar6M+DLDObiT7YpG9r6VGs2C2wc6rYBON7qG0bUJUkTMs7dO1NJ3tm2LwM+ALwAHAB2tmY7gcfa9gFgR5JLk1zL4A3bp9oU0OtJtra7du4c6iNJmoC1Y7RZB+xrd+D8ELC/qj6f5Algf5K7gFeAOwCq6kiS/cBzwBngnqo62451N/AQcBnweFskSROyaOhX1deB946ovwbcMk+fPcCeEfUZYKH3AyRJF5CfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smjoJ9mY5A+TPJ/kSJKPtvqVSQ4mebGtrxjqc2+SY0mOJrl1qH5TksNt3/1JcmGeliRplHGu9M8A/7iq/gawFbgnyXXAbuBQVW0GDrXHtH07gOuBbcADSda0Yz0I7AI2t2XbMj4XSdIiFg39qjpRVc+07deB54H1wHZgX2u2D7i9bW8HHqmqN6rqJeAYsCXJOuDyqnqiqgp4eKiPJGkCljSnn2QT8F7gSeCaqjoBgx8MwNWt2Xrg1aFus622vm3PrUuSJmTs0E/yo8DvAh+rqu8s1HRErRaoj/q3diWZSTJz+vTpcYcoSVrEWKGf5G0MAv8zVfV7rXyyTdnQ1qdafRbYONR9A3C81TeMqJ+jqvZW1XRVTU9NTY37XCRJixjn7p0AnwKer6pPDO06AOxs2zuBx4bqO5JcmuRaBm/YPtWmgF5PsrUd886hPpKkCVg7RpubgV8ADid5ttV+FbgP2J/kLuAV4A6AqjqSZD/wHIM7f+6pqrOt393AQ8BlwONtkSRNSAY30qxe09PTNTMzs9LDUMc27f7Cshzn5ftuW5bjSONI8nRVTc+t+4lcSerIONM7UheW64peWs280pekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JFFQz/Jp5OcSvKNodqVSQ4mebGtrxjad2+SY0mOJrl1qH5TksNt3/1JsvxPR5K0kHGu9B8Cts2p7QYOVdVm4FB7TJLrgB3A9a3PA0nWtD4PAruAzW2Ze0xJ0gW2aOhX1R8B/2tOeTuwr23vA24fqj9SVW9U1UvAMWBLknXA5VX1RFUV8PBQH0nShKw9z37XVNUJgKo6keTqVl8PfGWo3Wyr/d+2Pbc+UpJdDH4r4F3vetd5DlEabdPuL6z0EKQVs9xv5I6ap68F6iNV1d6qmq6q6ampqWUbnCT17nxD/2SbsqGtT7X6LLBxqN0G4HirbxhRlyRN0PlO7xwAdgL3tfVjQ/XPJvkE8OMM3rB9qqrOJnk9yVbgSeBO4N++pZFLF5n5ppVevu+2CY9EPVs09JN8Dng/cFWSWeCfMwj7/UnuAl4B7gCoqiNJ9gPPAWeAe6rqbDvU3QzuBLoMeLwtkqQJWjT0q+rD8+y6ZZ72e4A9I+ozwA1LGp0kaVn5iVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpyvp/IlbRM/KSuJsnQ119ZfpumdC6ndySpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHvGVTFz1vzZTGZ+hLq9RCP8z84JbOl9M7ktQRr/R10XAa5wf86gadL6/0JakjE7/ST7IN+C1gDfDJqrpv0mPQ6uXVvHRhTTT0k6wB/j3w08As8NUkB6rquUmOQ5NjiE/WUs+300H9mfSV/hbgWFV9CyDJI8B2wNBfIYZy35br9feHx8Vj0qG/Hnh16PEs8DfnNkqyC9jVHn43ydEJjG0prgL+dKUHMSbHeuFcTOO9oGPNx5f9kJ7bt+4nRhUnHfoZUatzClV7gb0XfjjnJ8lMVU2v9DjG4VgvnItpvBfTWOHiGu/FNFaY/N07s8DGoccbgOMTHoMkdWvSof9VYHOSa5NcAuwADkx4DJLUrYlO71TVmSS/AvxXBrdsfrqqjkxyDMtk1U49jeBYL5yLabwX01jh4hrvxTRWUnXOlLok6a8oP5ErSR0x9CWpI4b+GJL85yTPtuXlJM/O0+7lJIdbu5kJD/PNMfxGkv85NN4PztNuW5KjSY4l2T3pcbYx/KskLyT5epJHk7xznnYrdl4XO08ZuL/t/3qS901yfHPGsjHJHyZ5PsmRJB8d0eb9Sf586L+PX1+JsbaxLPi6rrJz++6hc/Zsku8k+dicNqvm3C6oqlyWsAD/Gvj1efa9DFy1wuP7DeCfLNJmDfBN4CeBS4CvAdetwFh/Bljbtj8OfHw1nddxzhPwQeBxBp9B2Qo8uYKv/TrgfW37HcD/GDHe9wOfX6kxLuV1XU3ndsR/F38C/MRqPbcLLV7pL0GSAP8A+NxKj+Ut+v7XYVTVXwBvfh3GRFXVl6rqTHv4FQaf21hNxjlP24GHa+ArwDuTrJv0QAGq6kRVPdO2XweeZ/Ap+IvVqjm3c9wCfLOqvr3SAzkfhv7S/C3gZFW9OM/+Ar6U5On2VRIr5Vfar8OfTnLFiP2jvg5jpcPhlxhc1Y2yUud1nPO0Gs8lSTYB7wWeHLH7p5J8LcnjSa6f7Mj+ksVe11V5bhl8vmi+C7/Vcm7n5R9RaZL8N+DHRuz6tap6rG1/mIWv8m+uquNJrgYOJnmhqv5okmMFHgR+k8H/UL/JYDrql+YeYkTfC3Lv7jjnNcmvAWeAz8xzmImc1xHGOU8TO5fjSvKjwO8CH6uq78zZ/QyDaYnvtvd7fh/YPOEhvmmx13U1nttLgA8B947YvZrO7bwM/aaqPrDQ/iRrgZ8HblrgGMfb+lSSRxlMDyx7OC021jcl+Y/A50fsmtjXYYxxXncCPwfcUm1idMQxJnJeRxjnPK2qrxZJ8jYGgf+Zqvq9ufuHfwhU1R8keSDJVVU18S8MG+N1XVXntvlZ4JmqOjl3x2o6twtxemd8HwBeqKrZUTuTvD3JO97cZvAm5TcmOL43xzE85/n35hnDqvg6jAz+oM4/Az5UVd+bp81KntdxztMB4M52p8lW4M+r6sSExveXtPecPgU8X1WfmKfNj7V2JNnCIANem9wovz+OcV7XVXNuh8z72/5qObeL8Up/fOfM4yX5cQZ//euDwDXAo+01Xwt8tqq+OPFRwr9MciODX4NfBj4yd6y1er4O498BlzL41R7gK1X1y6vlvM53npL8ctv/H4A/YHCXyTHge8AvTmJs87gZ+AXgcH5wW/GvAu+C74/37wN3JzkD/B9gx3y/YV1gI1/XVXxuSfIjDP4A1EeGasPjXS3ndkF+DYMkdcTpHUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOvL/AcCEJkv7gt3nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nodep, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcafbc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47544093954918626"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(nodep))/len(nodep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e17eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "today = today.strftime(\"%d%m%y\")\n",
    "\n",
    "torch.save(model.state_dict(),f'trained_models/model_{epoch}_{today}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10fd0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load=False\n",
    "if load:\n",
    "    model = GCN(hidden_channelse=128)\n",
    "    model.load_state_dict(torch.load(f'trained_models', f'model_{epoch}_{date}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(1.0244, grad_fn=<MulBackward0>)\n",
      "encoder tensor(1.0797, grad_fn=<MulBackward0>)\n",
      "edge tensor(0.5381, grad_fn=<MulBackward0>)\n",
      "both tensor(1.1271, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('decoder', sum(p.abs().sum() for p in model.f.parameters())/sum(p.numel() for p in model.f.parameters())*100)\n",
    "\n",
    "print('encoder', sum(p.abs().sum() for p in model.g1.parameters())/sum(p.numel() for p in model.g1.parameters())*100)\n",
    "print('edge', sum(p.abs().sum() for p in model.g2.parameters())/sum(p.numel() for p in model.g2.parameters())*100)\n",
    "print('both', sum(p.abs().sum() for p in model.g3.parameters())/sum(p.numel() for p in model.g3.parameters())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7371f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(osp.join(pointer, model_runs[k], 'trained_model', 'model.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d621ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pysr_loader=DataLoader(test_data[:50], batch_size=batch_size, shuffle=0, num_workers=4)    \n",
    "\n",
    "y_f = []\n",
    "y_g1 = []\n",
    "y_g2 = []\n",
    "y_g3 = []\n",
    "x_g1 = []\n",
    "y_t = []\n",
    "batch = []\n",
    "i=0\n",
    "for dat in pysr_loader:\n",
    "    print(i)\n",
    "    x_g1.append(dat.x.cpu().detach().numpy())\n",
    "    yg1=model.g1(dat.x)\n",
    "    y_g1.append(yg1.cpu().detach().numpy())\n",
    "    \n",
    "    adj = dat.edge_index\n",
    "    neighbours = yg1\n",
    "    xg2 = scatter_add(neighbours[adj[0]], adj[1], dim=0)\n",
    "    x_g2.append(xg2)\n",
    "    yg2=model.g2(xg2)\n",
    "    y_g2.append(yg2.cpu().detach().numpy())\n",
    "    \n",
    "    yg1[adj[1]]+=yg2[adj[1]]\n",
    "    \n",
    "    yg3 = model.g3(yg1)\n",
    "    y_g3.append(yg3.cpu().detach().numpy())\n",
    "    x_f = global_add_pool(yg3, dat.batch)\n",
    "    \n",
    "    yf = model.f(x_f)\n",
    "    y_f.append(yf.cpu().detach().numpy())\n",
    "    \n",
    "    batch.append(dat.batch.cpu().detach().numpy())\n",
    "    y_t.append(dat.y.cpu().detach().numpy())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e6d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=25\n",
    "vals, counts = np.unique(batch[0], return_counts=1)\n",
    "l = np.cumsum(counts)[N-1]\n",
    "x_g1_pysr=np.vstack(x_g1[0][:l])\n",
    "y_g1_pysr=np.vstack(y_g1[0][:l])\n",
    "y_g2_pysr=np.vstack(y_g2[0][:l])\n",
    "y_g3_pysr=np.vstack(y_g3[0][:l])\n",
    "y_f_pysr=np.vstack(y_f[0][:l])\n",
    "\n",
    "b_pysr = batch[0][:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92fb4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on julia -O3 --threads 4 /tmp/tmpyc0xp9yp/runfile.jl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Activating environment at `~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n",
      "\n",
      "Cycles per second: 6.440e+03\n",
      "Head worker occupation: 6.6%\n",
      "Progress: 3 / 1200 total iterations (0.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           9.573e-01  7.446e-02  (-0.39906436 + (2.5171049 * x1))\n",
      "7           7.673e-01  1.106e-01  (-0.2528663 + (x4 + (2.1287289 * x1)))\n",
      "8           7.581e-01  1.199e-02  ((2.0636811 * x1) + log_abs(0.94439185 + x4))\n",
      "9           6.789e-01  1.104e-01  (x1 + ((-0.57546425 * x0) + (3.2942095 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71885884 + (2.645293 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.491e+00  1.412e-01  ((2.6945295 * x1) + log_abs(-0.72173405 / x2))\n",
      "9           4.379e+00  2.510e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.017e+00  8.639e-02  ((2.9049654 * x1) + log_abs(sqrt_abs(log_abs(x2)) / x2))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.110e+03\n",
      "Head worker occupation: 2.9%\n",
      "Progress: 4 / 1200 total iterations (0.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765393 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25284228 + (x4 + (2.128747 * x1)))\n",
      "8           7.581e-01  1.199e-02  ((2.0636811 * x1) + log_abs(0.94439185 + x4))\n",
      "9           6.986e-01  8.170e-02  (x4 + ((-0.35670218 * x3) + (1.9270613 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71885884 + (2.645293 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.491e+00  1.412e-01  ((2.6945295 * x1) + log_abs(-0.72173405 / x2))\n",
      "9           4.379e+00  2.510e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.017e+00  8.639e-02  ((2.9049654 * x1) + log_abs(sqrt_abs(log_abs(x2)) / x2))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.930e+03\n",
      "Head worker occupation: 1.8%\n",
      "Progress: 7 / 1200 total iterations (0.583%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347527 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765505 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25280938 + (x4 + (2.128747 * x1)))\n",
      "9           7.660e-01  8.083e-04  (-0.24002542 + ((1.0874321 * x4) + (2.0947928 * x1)))\n",
      "10          7.295e-01  4.893e-02  (x1 - ((x4 * (log_abs(x4) + -1.0388708)) - x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7933848 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188488 + (2.6452794 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.431e+00  1.547e-01  (x0 + (-3.369158 * (x1 * log_abs(x2))))\n",
      "9           4.379e+00  1.168e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.305e+00  1.720e-02  (x0 + (2.9537868 * (x1 * log_abs(1.1906661 / x2))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.860e+03\n",
      "Head worker occupation: 1.3%\n",
      "Progress: 10 / 1200 total iterations (0.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979004 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "7           6.145e-01  2.423e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.867392 + (x1 + (-2.314182 * sqrt_abs(x2))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7936423 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188475 + (2.645304 * x1))\n",
      "6           5.024e+00  2.188e-01  ((x1 / 0.36871853) - log_abs(x1))\n",
      "7           4.676e+00  7.183e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.509e+00  3.631e-02  ((x1 / 0.37334132) - log_abs(x2 * 1.2066805))\n",
      "9           4.318e+00  4.324e-02  ((x1 / 0.34495905) - log_abs(sqrt_abs(x2) * x1))\n",
      "10          4.201e+00  2.752e-02  ((8.892884 * x1) + (-10.245522 * (x2 * sqrt_abs(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.610e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 11 / 1200 total iterations (0.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7936423 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188475 + (2.645304 * x1))\n",
      "6           5.024e+00  2.188e-01  ((x1 / 0.36871853) - log_abs(x1))\n",
      "7           4.676e+00  7.183e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.509e+00  3.631e-02  ((x1 / 0.37334132) - log_abs(x2 * 1.2066805))\n",
      "9           4.318e+00  4.324e-02  ((x1 / 0.34495905) - log_abs(sqrt_abs(x2) * x1))\n",
      "10          4.201e+00  2.752e-02  ((8.892884 * x1) + (-10.245522 * (x2 * sqrt_abs(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 3.380e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 13 / 1200 total iterations (1.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71897423 + (2.6452804 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 - log_abs(x2)) + x1)\n",
      "7           4.676e+00  4.954e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.560e+00  2.520e-02  ((x1 - (log_abs(x2) - x0)) + x1)\n",
      "10          4.217e+00  3.903e-02  (-0.93081266 + ((-1.5788529 * log_abs(x2)) + (2.7227342 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.080e+03\n",
      "Head worker occupation: 0.8%\n",
      "Progress: 14 / 1200 total iterations (1.167%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7940874 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188683 + (2.6452758 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 - log_abs(x2)) + x1)\n",
      "8           4.491e+00  4.498e-02  ((2.6943352 * x1) + log_abs(0.7219004 / x2))\n",
      "10          3.967e+00  6.198e-02  ((3.6765597 * x1) + log_abs(-0.8480846 + (0.8631841 / x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.330e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 17 / 1200 total iterations (1.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3798684 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.95245224 * log10_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.965e-01  3.125e-02  (x1 + (-0.93270797 * log10_abs(0.06882628 + x2)))\n",
      "9           5.494e-01  8.224e-02  (x1 - log10_abs((x3 * log10_abs(x0)) + x2))\n",
      "10          5.306e-01  3.486e-02  (x1 - log10_abs((x3 * log10_abs(sqrt_abs(x0))) + x2))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71884656 + (2.6452959 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "7           4.044e+00  1.946e-01  ((-9.898346 * x2) + (8.19939 * x1))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.100e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 18 / 1200 total iterations (1.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3798684 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.95245224 * log10_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.965e-01  3.125e-02  (x1 + (-0.93270797 * log10_abs(0.06882628 + x2)))\n",
      "9           5.494e-01  8.224e-02  (x1 - log10_abs((x3 * log10_abs(x0)) + x2))\n",
      "10          5.306e-01  3.486e-02  (x1 - log10_abs((x3 * log10_abs(sqrt_abs(x0))) + x2))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.150e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 20 / 1200 total iterations (1.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37978694 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41363257 * log_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.981e-01  2.865e-02  (x1 + (-0.92408365 * log10_abs(0.05345475 + x2)))\n",
      "9           5.918e-01  1.052e-02  (x1 - (log10_abs(x2) * sqrt_abs(x0 + 1.1087832)))\n",
      "10          5.659e-01  4.476e-02  (x1 + (-1.07813 * log10_abs(x2 + (-0.09936239 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.076545 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25267908 + (x4 + (2.1288564 * x1)))\n",
      "9           6.693e-01  6.832e-02  (-0.5448855 + ((-0.5488192 * x3) + (2.3172386 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 2.680e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 21 / 1200 total iterations (1.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.990e-01  8.240e-02  (x1 + 0.34660563)\n",
      "4           6.190e-01  2.553e-01  (x1 - log10_abs(x2))\n",
      "7           5.908e-01  1.554e-02  ((2.9686167 * x1) + (-3.5632546 * x2))\n",
      "8           5.679e-01  3.962e-02  ((2.3849034 - log_abs(x1)) * (x1 - x2))\n",
      "10          5.659e-01  1.701e-03  (x1 + (-1.07813 * log10_abs(x2 + (-0.09936239 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.076545 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25267908 + (x4 + (2.1288564 * x1)))\n",
      "9           6.693e-01  6.832e-02  (-0.5448855 + ((-0.5488192 * x3) + (2.3172386 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.990e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 24 / 1200 total iterations (2.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979323 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.143e-01  3.843e-03  (x1 - log10_abs(x2 * 1.2160699))\n",
      "8           5.966e-01  1.461e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "10          5.663e-01  2.607e-02  (x1 - log10_abs((x2 + (x3 * -0.09657265)) * -1.0948982))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765564 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.2530826 + (x4 + (2.1288114 * x1)))\n",
      "9           6.986e-01  4.684e-02  (x4 + ((-0.35670036 * x3) + (1.9270647 * x1)))\n",
      "10          6.585e-01  5.921e-02  (x4 + ((3.4497137 * x2) + (x3 * log10_abs(x0))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.770e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 25 / 1200 total iterations (2.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979323 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.143e-01  3.843e-03  (x1 - log10_abs(x2 * 1.2160699))\n",
      "8           5.966e-01  1.461e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "10          5.663e-01  2.607e-02  (x1 - log10_abs((x2 + (x3 * -0.09657265)) * -1.0948982))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.131e+00  4.509e-01  (2.5918505 * x1)\n",
      "4           1.117e+00  1.246e-02  (sqrt_abs(5.5143814) * x1)\n",
      "5           8.352e-01  2.909e-01  ((x1 * 1.9893233) + x4)\n",
      "7           7.673e-01  4.239e-02  (-0.25282595 + (x4 + (2.128735 * x1)))\n",
      "8           6.761e-01  1.265e-01  (x4 + (x1 * sqrt_abs(4.6921225 / x1)))\n",
      "10          6.077e-01  5.331e-02  (x2 + (x4 + (x1 * log_abs(5.268682 / x1))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.750e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 27 / 1200 total iterations (2.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797861 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41367182 * log_abs(x2)))\n",
      "8           5.966e-01  1.780e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.265e+00  3.950e-01  (x1 + x1)\n",
      "4           1.111e+00  1.295e-01  (x1 * sqrt_abs(6.014003))\n",
      "5           8.822e-01  2.308e-01  ((x1 * 3.2053354) - x0)\n",
      "6           8.366e-01  5.304e-02  (x1 * sqrt_abs(-6.5326552 / x1))\n",
      "7           7.727e-01  7.943e-02  ((-0.6377825 * x0) + (2.913713 * x1))\n",
      "8           6.761e-01  1.336e-01  (x4 + (x1 * sqrt_abs(4.6921225 / x1)))\n",
      "9           6.611e-01  2.232e-02  (-0.3417246 + ((-0.59988934 * x0) + (2.9557881 * x1)))\n",
      "10          6.077e-01  8.430e-02  (x2 + (x4 + (x1 * log_abs(5.268682 / x1))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.620e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 28 / 1200 total iterations (2.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797861 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41367182 * log_abs(x2)))\n",
      "8           5.966e-01  1.780e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.232e+00  4.080e-01  (x1 / 0.48811185)\n",
      "5           8.337e-01  1.954e-01  ((x1 + x4) + x1)\n",
      "8           8.279e-01  2.349e-03  (x1 - ((x3 - x1) + sqrt_abs(x2)))\n",
      "9           6.693e-01  2.127e-01  (-0.5449041 + ((-0.5488431 * x3) + (2.317193 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 2.770e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 30 / 1200 total iterations (2.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972298 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85042274 / x2))\n",
      "8           6.078e-01  5.104e-03  (x1 + log10_abs(-0.3060487 + (0.8593486 / x2)))\n",
      "9           5.971e-01  1.785e-02  ((x1 - log10_abs(x2 * sqrt_abs(x1))) - 0.18158987)\n",
      "10          5.677e-01  5.047e-02  (x1 + log10_abs((-1.0497826 / x2) + (-0.7018149 * x3)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.232e+00  4.080e-01  (x1 / 0.48811185)\n",
      "5           8.337e-01  1.954e-01  ((x1 + x4) + x1)\n",
      "8           8.279e-01  2.349e-03  (x1 - ((x3 - x1) + sqrt_abs(x2)))\n",
      "9           6.693e-01  2.127e-01  (-0.5449041 + ((-0.5488431 * x3) + (2.317193 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "3           7.265e+00  1.273e-01  (x1 + x1)\n",
      "4           6.749e+00  7.369e-02  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71886116 + (2.6453934 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "8           4.560e+00  3.737e-02  (((x0 + x1) + x1) - log_abs(x2))\n",
      "10          4.217e+00  3.903e-02  (-0.9306045 + ((-1.5786276 * log_abs(x2)) + (2.7231658 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.210e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 33 / 1200 total iterations (2.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972295 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85011387 / x2))\n",
      "7           5.908e-01  3.858e-02  ((-3.5634954 * x2) + (2.96877 * x1))\n",
      "9           5.882e-01  2.222e-03  (-0.073791474 + ((3.1524632 * x1) + (-3.8719606 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347527 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.07655 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.2528399 + (x4 + (2.128747 * x1)))\n",
      "9           7.532e-01  9.242e-03  (-0.1331652 + (x2 + (x4 + (1.5579417 * x1))))\n",
      "10          6.607e-01  1.311e-01  (x4 + ((1.8001357 * x1) + log10_abs(0.34272045 + x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "3           7.265e+00  1.273e-01  (x1 + x1)\n",
      "4           6.749e+00  7.369e-02  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71886116 + (2.6453934 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "8           4.560e+00  3.737e-02  (((x0 + x1) + x1) - log_abs(x2))\n",
      "10          4.217e+00  3.903e-02  (-0.9306045 + ((-1.5786276 * log_abs(x2)) + (2.7231658 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.070e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 36 / 1200 total iterations (3.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972295 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85011387 / x2))\n",
      "7           5.908e-01  3.858e-02  ((-3.5634954 * x2) + (2.96877 * x1))\n",
      "9           5.882e-01  2.222e-03  (-0.073791474 + ((3.1524632 * x1) + (-3.8719606 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.793656 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188273 + (2.6452773 * x1))\n",
      "6           5.172e+00  1.898e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  ((x1 + (x0 + x4)) - log_abs(x2))\n",
      "10          4.112e+00  4.857e-02  (((x1 + x1) - log_abs(x1 - 0.2593729)) / 0.6445904)\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.480e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 39 / 1200 total iterations (3.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797341 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(-0.8504216 / x2))\n",
      "7           6.119e-01  3.561e-03  (x1 + sqrt_abs(log10_abs(-0.36682373 + x1)))\n",
      "9           5.966e-01  1.267e-02  (x1 + log10_abs(log10_abs(0.15950276 * x3) / x2))\n",
      "10          5.824e-01  2.393e-02  (x1 + log10_abs(-0.90379727 / (x2 + (0.115976155 * x0))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.793656 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188273 + (2.6452773 * x1))\n",
      "6           5.172e+00  1.898e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  ((x1 + (x0 + x4)) - log_abs(x2))\n",
      "10          4.112e+00  4.857e-02  (((x1 + x1) - log_abs(x1 - 0.2593729)) / 0.6445904)\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.480e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 42 / 1200 total iterations (3.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37967104 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "8           5.698e-01  2.072e-02  (1.8674098 + (x1 + (-2.314192 * sqrt_abs(x2))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188429 + (2.6452808 * x1))\n",
      "6           4.913e+00  2.411e-01  (x1 + (x1 - log_abs(x2)))\n",
      "8           4.679e+00  2.442e-02  (x1 + (x1 - log_abs(x1 - 0.45799425)))\n",
      "10          3.656e+00  1.234e-01  (x0 + (x1 + (-1.9220711 * log_abs(-0.39283225 + x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killing process... will return when done.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "g1_equations = pysr(\n",
    "    X=x_g1_pysr, y=y_g1_pysr,\n",
    "    procs=4,\n",
    "    niterations=20,\n",
    "    populations=20,\n",
    "    useFrequency=True,\n",
    "    multithreading=True, \n",
    "    binary_operators=[\"plus\", \"sub\", \"mult\", \"div\"],\n",
    "    unary_operators = ['log10_abs', 'sqrt_abs', 'exp', 'log'], ##still need a general power law\n",
    "    batching=1, \n",
    "    batchSize=256,\n",
    "    maxsize=10, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ef6a182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                                4\n",
       "MSE                                                0.618991\n",
       "score                                              0.253895\n",
       "Equation                               (x1 - log10_abs(x2))\n",
       "sympy_format                      x1 - log(Abs(x2))/log(10)\n",
       "lambda_format    PySRFunction(X=>x1 - log(Abs(x2))/log(10))\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[0].sort_values(by='score', ascending=False).iloc[0]\n",
    "a=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3ce5b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                          3\n",
       "MSE                                          1.143048\n",
       "score                                        0.445626\n",
       "Equation                            (x1 / 0.37977126)\n",
       "sympy_format                      2.63316397349289*x1\n",
       "lambda_format    PySRFunction(X=>2.63316397349289*x1)\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[1].sort_values(by='score', ascending=False).iloc[0]\n",
    "b=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33090e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                   3\n",
       "MSE                                   6.751929\n",
       "score                                 0.298143\n",
       "Equation                      (2.7937005 * x1)\n",
       "sympy_format                      2.7937005*x1\n",
       "lambda_format    PySRFunction(X=>2.7937005*x1)\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[2].sort_values(by='score', ascending=False).iloc[0]\n",
    "c=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5414aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_an_pysr = np.vstack([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838585ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on julia -O3 --threads 4 /tmp/tmpgyms7yzv/runfile.jl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Activating environment at `~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n",
      "\n",
      "Cycles per second: 5.180e+03\n",
      "Head worker occupation: 8.3%\n",
      "Progress: 2 / 1200 total iterations (0.167%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2790511\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.2852532 + (-0.26651594 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.950e+03\n",
      "Head worker occupation: 5.1%\n",
      "Progress: 3 / 1200 total iterations (0.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.440e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 4 / 1200 total iterations (0.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.710e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 5 / 1200 total iterations (0.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.430e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 6 / 1200 total iterations (0.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.285257 + (-0.2665256 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.740e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 8 / 1200 total iterations (0.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.750e+03\n",
      "Head worker occupation: 0.8%\n",
      "Progress: 9 / 1200 total iterations (0.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 3.420e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 10 / 1200 total iterations (0.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.350e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 13 / 1200 total iterations (1.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.450e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 15 / 1200 total iterations (1.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.093e-03  sqrt_abs(1.9594429 + (-0.6206558 * x1))\n",
      "8           5.891e-01  7.699e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.648e-01  2.098e-02  sqrt_abs(0.11480782 + exp(1.308776 + (-0.45345652 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.080e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 16 / 1200 total iterations (1.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2788731\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.648e-01  2.098e-02  sqrt_abs(0.11480782 + exp(1.308776 + (-0.45345652 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.810e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 19 / 1200 total iterations (1.583%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2786434\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.110e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 21 / 1200 total iterations (1.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 5.100e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 22 / 1200 total iterations (1.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.060e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 23 / 1200 total iterations (1.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.730e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 25 / 1200 total iterations (2.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25174072 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852515 + (-0.2665252 * x1))\n",
      "6           5.982e-01  2.083e-03  sqrt_abs(1.9546335 + (-0.6191466 * x1))\n",
      "7           5.891e-01  1.541e-02  exp(0.6601062 + (-0.19049618 * exp(x1)))\n",
      "9           5.862e-01  2.450e-03  exp((x1 + (sqrt_abs(x1) - 1.815573)) * -0.24319673)\n",
      "10          5.570e-01  5.109e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.650e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 28 / 1200 total iterations (2.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25174072 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852579 + (-0.26652578 * x1))\n",
      "6           5.982e-01  2.072e-03  sqrt_abs(1.9627051 + (-0.62186176 * x1))\n",
      "7           5.873e-01  1.847e-02  (sqrt_abs(sqrt_abs(9.484525) - x1) + -0.39439014)\n",
      "8           5.845e-01  4.689e-03  (-0.30447757 + sqrt_abs(2.8036215 + (-0.8870912 * x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.130e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 30 / 1200 total iterations (2.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2789322\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852509 + (-0.26652473 * x1))\n",
      "6           5.982e-01  2.082e-03  sqrt_abs(1.9564418 + (-0.61975557 * x1))\n",
      "7           5.891e-01  1.541e-02  exp(0.6601307 + (-0.19048771 * exp(x1)))\n",
      "8           5.845e-01  7.735e-03  (-0.30447757 + sqrt_abs(2.8036215 + (-0.8870912 * x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.150e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 32 / 1200 total iterations (2.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852594 + (-0.26652542 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 4.950e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 35 / 1200 total iterations (2.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852598 + (-0.26652578 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.910e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 36 / 1200 total iterations (3.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852598 + (-0.26652578 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.030e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 39 / 1200 total iterations (3.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852643 + (-0.26654008 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.870e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 41 / 1200 total iterations (3.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2790481\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517328 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852972 + (-0.26651946 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "7           5.752e-01  1.888e-02  log10_abs(exp(1.9263862 - x1) + x2)\n",
      "8           5.707e-01  7.786e-03  log10_abs(exp(exp(0.74600375) - x1) + x2)\n",
      "9           5.671e-01  6.467e-03  log10_abs(x2 + exp(2.390812 + (-0.8634285 * x1)))\n",
      "10          5.169e-01  9.272e-02  log10_abs(x2 + exp(4.511248 + (-1.0051906 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    }
   ],
   "source": [
    "g2_equations = pysr(\n",
    "    X=y_g1_pysr, y=y_g2_pysr,\n",
    "    procs=4,\n",
    "    niterations=20,\n",
    "    populations=20,\n",
    "    useFrequency=True,\n",
    "    multithreading=True, \n",
    "    binary_operators=[\"plus\", \"sub\", \"mult\", \"div\", 'pow'],\n",
    "    unary_operators = ['log10_abs', 'sqrt_abs', 'exp', 'log'], ##still need a general power law\n",
    "    batching=1, \n",
    "    batchSize=256,\n",
    "    maxsize=10, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aca42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
