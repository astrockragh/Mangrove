{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e649e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle, time, os, random\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.loader import DataLoader\n",
    "# accelerate huggingface to GPU\n",
    "if torch.cuda.is_available():\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator()\n",
    "    device = accelerator.device\n",
    "from pysr import pysr, best\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "print('Loading data')\n",
    "\n",
    "case='vlarge_all_4t_z0.0_standard_raw'\n",
    "\n",
    "datat=pickle.load(open(osp.expanduser(f'~/../../../scratch/gpfs/cj1223/GraphStorage/{case}/data.pkl'), 'rb'))\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "data=[]\n",
    "for d in datat:\n",
    "    data.append(Data(x=d.x[:,[0,3,4,19,20]], edge_index=d.edge_index, edge_attr=d.edge_attr, y=d.y[0]))\n",
    "\n",
    "try:\n",
    "    n_targ=len(data[0].y)\n",
    "except:\n",
    "    n_targ=1\n",
    "n_feat=len(data[0].x[0])\n",
    "n_feat, n_targ\n",
    "\n",
    "print('Loaded data')\n",
    "\n",
    "from torch.nn import ReLU, Linear, Module, LayerNorm, Sequential\n",
    "class MLP(Module):\n",
    "    def __init__(self, n_in, n_out, hidden=128, nlayers=2, layer_norm=True):\n",
    "        super().__init__()\n",
    "        layers = [Linear(n_in, hidden), ReLU()]\n",
    "        for i in range(nlayers):\n",
    "            layers.append(Linear(hidden, hidden))\n",
    "            layers.append(ReLU()) \n",
    "        if layer_norm:\n",
    "            layers.append(LayerNorm(hidden)) #yay\n",
    "        layers.append(Linear(hidden, n_out))\n",
    "        self.mlp = Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461c14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_outs=3, hidden_channels=64, n_feat=5, n_targ=1):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g1 = MLP(n_feat, n_outs, hidden = hidden_channels)\n",
    "        self.g2 = MLP(n_outs, n_outs,  hidden = hidden_channels)\n",
    "        self.g3= MLP(n_outs, n_outs, hidden = hidden_channels) \n",
    "    \n",
    "        self.f = MLP(n_outs, n_targ,  hidden = hidden_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        \n",
    "        x = self.g1(x) # NODE ENCODER\n",
    "        \n",
    "#         global adj, batch1, xe\n",
    "        adj = edge_index\n",
    "#         global neighbours\n",
    "#         global N_sum\n",
    "#         neighbours = x\n",
    "#         batch1=batch\n",
    "        \n",
    "        N_sum = scatter_add(x[adj[0]],adj[1], dim=0) #ADD NEIGHBORHOOD NODES\n",
    "        xe = self.g2(N_sum) #ENCODE EDGE SUM\n",
    "        x[adj[1]]+=xe[adj[1]] #only add where we have receiving nodes TO UPDATA X\n",
    "        x = self.g3(x) #MLP ON EDGE ADDED FEATURES\n",
    "\n",
    "        x = global_add_pool(x, batch)\n",
    "\n",
    "        x = self.f(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = GCN(hidden_channels=64)\n",
    "next(model.parameters()).is_cuda ##check number one\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.L1Loss()\n",
    "# criterion = torch.nn.SmoothL1Loss(beta=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "030cb3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU  False\n"
     ]
    }
   ],
   "source": [
    "# data=data\n",
    "n_epochs=50\n",
    "n_trials=1\n",
    "batch_size=int(2**8) # 8-256\n",
    "split=0.8\n",
    "test_data=data[int(len(data)*split):]\n",
    "train_data=data[:int(len(data)*split)]\n",
    "# train_data, test_data=train_test_split(data, test_size=0.2)\n",
    "l1_lambda = 1e-4\n",
    "l2_lambda = 0\n",
    "hidden = 128\n",
    "\n",
    "yss, preds=[],[]\n",
    "model = GCN(hidden_channels=hidden)\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=1, num_workers=4)\n",
    "\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=0, num_workers=4)    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "print('GPU ', next(model.parameters()).is_cuda)\n",
    "# Initialize our train function\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for data in tqdm(train_loader, total=len(train_loader)): \n",
    "#         print('batch')\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        loss = criterion(out, data.y.view(-1,1)) \n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "\n",
    "\n",
    "        loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "#     print(loss, l1_norm*l1_lambda, l2_norm*l2_lambda)\n",
    " # test function\n",
    "\n",
    "def test(loader): ##### transform back missing\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    ys = []\n",
    "    with torch.no_grad(): ##this solves it!!!\n",
    "        for dat in tqdm(loader, total=len(loader)): \n",
    "            \n",
    "            out = model(dat.x, dat.edge_index, dat.batch) \n",
    "            ys.append(dat.y.view(-1,n_targ))\n",
    "            outs.append(out)\n",
    "    outss=torch.vstack(outs)\n",
    "    yss=torch.vstack(ys)\n",
    "    return torch.std(outss - yss, axis=0), outss, yss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbf75f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:41<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:42<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [01:01<00:00,  5.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 86/86 [00:16<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train scatter: [0.1776] \n",
      "         Test scatter: [0.1765]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:43<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:43<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [01:01<00:00,  5.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 86/86 [00:16<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train scatter: [0.147] \n",
      "         Test scatter: [0.1467]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:43<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [02:42<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 341/341 [01:01<00:00,  5.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 86/86 [00:16<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train scatter: [0.1737] \n",
      "         Test scatter: [0.1748]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                | 25/341 [00:14<03:05,  1.71it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/cj1223/.conda/envs/juptorch_julia/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1892/743361013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1892/3949525891.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml1_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml2_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_acc, te_acc = [], []\n",
    "start=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    print(epoch)\n",
    "    train()\n",
    "    if (epoch+1)%2==0:\n",
    "        train_acc, _ , _ = test(train_loader)\n",
    "        test_acc, _ , _ = test(test_loader)\n",
    "        tr_acc.append(train_acc.cpu())\n",
    "        te_acc.append(test_acc.cpu())\n",
    "        print(f'Epoch: {epoch+1:03d}, Train scatter: {np.round(train_acc.cpu().numpy(), 4)} \\n \\\n",
    "        Test scatter: {np.round(test_acc.cpu().numpy(), 4)}')\n",
    "stop=time.time()\n",
    "spent=stop-start\n",
    "print(f\"{spent:.2f} seconds spent training, {spent/n_epochs:.3f} seconds per epoch. Processed {len(data)*split*n_epochs/spent:.0f} trees per second\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e17eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "today = today.strftime(\"%d%m%y\")\n",
    "\n",
    "torch.save(model.state_dict(),f'trained_models/model_{epoch}_{today}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10fd0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load=False\n",
    "if load:\n",
    "    model = GCN(hidden_channelse=128)\n",
    "    model.load_state_dict(torch.load(f'trained_models', f'model_{epoch}_{date}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c81daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder tensor(1.0244, grad_fn=<MulBackward0>)\n",
      "encoder tensor(1.0797, grad_fn=<MulBackward0>)\n",
      "edge tensor(0.5381, grad_fn=<MulBackward0>)\n",
      "both tensor(1.1271, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('decoder', sum(p.abs().sum() for p in model.f.parameters())/sum(p.numel() for p in model.f.parameters())*100)\n",
    "\n",
    "print('encoder', sum(p.abs().sum() for p in model.g1.parameters())/sum(p.numel() for p in model.g1.parameters())*100)\n",
    "print('edge', sum(p.abs().sum() for p in model.g2.parameters())/sum(p.numel() for p in model.g2.parameters())*100)\n",
    "print('both', sum(p.abs().sum() for p in model.g3.parameters())/sum(p.numel() for p in model.g3.parameters())*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7371f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(osp.join(pointer, model_runs[k], 'trained_model', 'model.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d621ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pysr_loader=DataLoader(test_data[:50], batch_size=batch_size, shuffle=0, num_workers=4)    \n",
    "\n",
    "y_f = []\n",
    "y_g1 = []\n",
    "y_g2 = []\n",
    "y_g3 = []\n",
    "x_g1 = []\n",
    "y_t = []\n",
    "batch = []\n",
    "i=0\n",
    "for dat in pysr_loader:\n",
    "    print(i)\n",
    "    x_g1.append(dat.x.cpu().detach().numpy())\n",
    "    yg1=model.g1(dat.x)\n",
    "    y_g1.append(yg1.cpu().detach().numpy())\n",
    "    \n",
    "    adj = dat.edge_index\n",
    "    neighbours = yg1\n",
    "    xg2 = scatter_add(neighbours[adj[0]], adj[1], dim=0)\n",
    "    x_g2.append(xg2)\n",
    "    yg2=model.g2(xg2)\n",
    "    y_g2.append(yg2.cpu().detach().numpy())\n",
    "    \n",
    "    yg1[adj[1]]+=yg2[adj[1]]\n",
    "    \n",
    "    yg3 = model.g3(yg1)\n",
    "    y_g3.append(yg3.cpu().detach().numpy())\n",
    "    x_f = global_add_pool(yg3, dat.batch)\n",
    "    \n",
    "    yf = model.f(x_f)\n",
    "    y_f.append(yf.cpu().detach().numpy())\n",
    "    \n",
    "    batch.append(dat.batch.cpu().detach().numpy())\n",
    "    y_t.append(dat.y.cpu().detach().numpy())\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e6d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=25\n",
    "vals, counts = np.unique(batch[0], return_counts=1)\n",
    "l = np.cumsum(counts)[N-1]\n",
    "x_g1_pysr=np.vstack(x_g1[0][:l])\n",
    "y_g1_pysr=np.vstack(y_g1[0][:l])\n",
    "y_g2_pysr=np.vstack(y_g2[0][:l])\n",
    "y_g3_pysr=np.vstack(y_g3[0][:l])\n",
    "y_f_pysr=np.vstack(y_f[0][:l])\n",
    "\n",
    "b_pysr = batch[0][:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92fb4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on julia -O3 --threads 4 /tmp/tmpyc0xp9yp/runfile.jl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Activating environment at `~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n",
      "\n",
      "Cycles per second: 6.440e+03\n",
      "Head worker occupation: 6.6%\n",
      "Progress: 3 / 1200 total iterations (0.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           9.573e-01  7.446e-02  (-0.39906436 + (2.5171049 * x1))\n",
      "7           7.673e-01  1.106e-01  (-0.2528663 + (x4 + (2.1287289 * x1)))\n",
      "8           7.581e-01  1.199e-02  ((2.0636811 * x1) + log_abs(0.94439185 + x4))\n",
      "9           6.789e-01  1.104e-01  (x1 + ((-0.57546425 * x0) + (3.2942095 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71885884 + (2.645293 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.491e+00  1.412e-01  ((2.6945295 * x1) + log_abs(-0.72173405 / x2))\n",
      "9           4.379e+00  2.510e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.017e+00  8.639e-02  ((2.9049654 * x1) + log_abs(sqrt_abs(log_abs(x2)) / x2))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.110e+03\n",
      "Head worker occupation: 2.9%\n",
      "Progress: 4 / 1200 total iterations (0.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765393 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25284228 + (x4 + (2.128747 * x1)))\n",
      "8           7.581e-01  1.199e-02  ((2.0636811 * x1) + log_abs(0.94439185 + x4))\n",
      "9           6.986e-01  8.170e-02  (x4 + ((-0.35670218 * x3) + (1.9270613 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71885884 + (2.645293 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.491e+00  1.412e-01  ((2.6945295 * x1) + log_abs(-0.72173405 / x2))\n",
      "9           4.379e+00  2.510e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.017e+00  8.639e-02  ((2.9049654 * x1) + log_abs(sqrt_abs(log_abs(x2)) / x2))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.930e+03\n",
      "Head worker occupation: 1.8%\n",
      "Progress: 7 / 1200 total iterations (0.583%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347527 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765505 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25280938 + (x4 + (2.128747 * x1)))\n",
      "9           7.660e-01  8.083e-04  (-0.24002542 + ((1.0874321 * x4) + (2.0947928 * x1)))\n",
      "10          7.295e-01  4.893e-02  (x1 - ((x4 * (log_abs(x4) + -1.0388708)) - x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7933848 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188488 + (2.6452794 * x1))\n",
      "7           5.172e+00  9.491e-02  (x1 + log_abs(exp(x0) / x2))\n",
      "8           4.431e+00  1.547e-01  (x0 + (-3.369158 * (x1 * log_abs(x2))))\n",
      "9           4.379e+00  1.168e-02  ((2.532024 * x1) + log_abs(log_abs(x0) / x2))\n",
      "10          4.305e+00  1.720e-02  (x0 + (2.9537868 * (x1 * log_abs(1.1906661 / x2))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.860e+03\n",
      "Head worker occupation: 1.3%\n",
      "Progress: 10 / 1200 total iterations (0.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979004 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "7           6.145e-01  2.423e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.867392 + (x1 + (-2.314182 * sqrt_abs(x2))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7936423 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188475 + (2.645304 * x1))\n",
      "6           5.024e+00  2.188e-01  ((x1 / 0.36871853) - log_abs(x1))\n",
      "7           4.676e+00  7.183e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.509e+00  3.631e-02  ((x1 / 0.37334132) - log_abs(x2 * 1.2066805))\n",
      "9           4.318e+00  4.324e-02  ((x1 / 0.34495905) - log_abs(sqrt_abs(x2) * x1))\n",
      "10          4.201e+00  2.752e-02  ((8.892884 * x1) + (-10.245522 * (x2 * sqrt_abs(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.610e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 11 / 1200 total iterations (0.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7936423 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188475 + (2.645304 * x1))\n",
      "6           5.024e+00  2.188e-01  ((x1 / 0.36871853) - log_abs(x1))\n",
      "7           4.676e+00  7.183e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.509e+00  3.631e-02  ((x1 / 0.37334132) - log_abs(x2 * 1.2066805))\n",
      "9           4.318e+00  4.324e-02  ((x1 / 0.34495905) - log_abs(sqrt_abs(x2) * x1))\n",
      "10          4.201e+00  2.752e-02  ((8.892884 * x1) + (-10.245522 * (x2 * sqrt_abs(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 3.380e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 13 / 1200 total iterations (1.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.71897423 + (2.6452804 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 - log_abs(x2)) + x1)\n",
      "7           4.676e+00  4.954e-02  ((x1 / sqrt_abs(-0.11523554)) - log_abs(x2))\n",
      "8           4.560e+00  2.520e-02  ((x1 - (log_abs(x2) - x0)) + x1)\n",
      "10          4.217e+00  3.903e-02  (-0.93081266 + ((-1.5788529 * log_abs(x2)) + (2.7227342 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.080e+03\n",
      "Head worker occupation: 0.8%\n",
      "Progress: 14 / 1200 total iterations (1.167%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797928 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.178e-01  9.897e-04  (x1 - (0.009313339 + log10_abs(x2)))\n",
      "7           6.145e-01  5.290e-03  (x1 - (log_abs(sqrt_abs(x2)) - -0.10132865))\n",
      "8           5.698e-01  7.561e-02  (1.8673731 + (x1 + (-2.3141558 * sqrt_abs(x2))))\n",
      "10          5.679e-01  1.624e-03  (x1 + (-1.0557032 * log10_abs(x2 + (-0.1134993 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7940874 * x1)\n",
      "5           6.253e+00  3.838e-02  (0.7188683 + (2.6452758 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 - log_abs(x2)) + x1)\n",
      "8           4.491e+00  4.498e-02  ((2.6943352 * x1) + log_abs(0.7219004 / x2))\n",
      "10          3.967e+00  6.198e-02  ((3.6765597 * x1) + log_abs(-0.8480846 + (0.8631841 / x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.330e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 17 / 1200 total iterations (1.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3798684 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.95245224 * log10_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.965e-01  3.125e-02  (x1 + (-0.93270797 * log10_abs(0.06882628 + x2)))\n",
      "9           5.494e-01  8.224e-02  (x1 - log10_abs((x3 * log10_abs(x0)) + x2))\n",
      "10          5.306e-01  3.486e-02  (x1 - log10_abs((x3 * log10_abs(sqrt_abs(x0))) + x2))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71884656 + (2.6452959 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "7           4.044e+00  1.946e-01  ((-9.898346 * x2) + (8.19939 * x1))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.100e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 18 / 1200 total iterations (1.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3798684 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.95245224 * log10_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.965e-01  3.125e-02  (x1 + (-0.93270797 * log10_abs(0.06882628 + x2)))\n",
      "9           5.494e-01  8.224e-02  (x1 - log10_abs((x3 * log10_abs(x0)) + x2))\n",
      "10          5.306e-01  3.486e-02  (x1 - log10_abs((x3 * log10_abs(sqrt_abs(x0))) + x2))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.088e+00  4.701e-01  (4.234271 * x2)\n",
      "5           8.302e-01  1.354e-01  (x4 - (x1 / -0.49075502))\n",
      "7           7.658e-01  4.035e-02  (x1 + (x4 + (1.9295096 * x2)))\n",
      "10          7.068e-01  2.676e-02  (x1 + (x4 + (x2 * exp(sqrt_abs(log_abs(x2))))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.150e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 20 / 1200 total iterations (1.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37978694 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41363257 * log_abs(x2)))\n",
      "7           6.155e-01  4.403e-03  (x1 - log10_abs(log10_abs(-1.008061) + x2))\n",
      "8           5.981e-01  2.865e-02  (x1 + (-0.92408365 * log10_abs(0.05345475 + x2)))\n",
      "9           5.918e-01  1.052e-02  (x1 - (log10_abs(x2) * sqrt_abs(x0 + 1.1087832)))\n",
      "10          5.659e-01  4.476e-02  (x1 + (-1.07813 * log10_abs(x2 + (-0.09936239 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.076545 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25267908 + (x4 + (2.1288564 * x1)))\n",
      "9           6.693e-01  6.832e-02  (-0.5448855 + ((-0.5488192 * x3) + (2.3172386 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 2.680e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 21 / 1200 total iterations (1.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.990e-01  8.240e-02  (x1 + 0.34660563)\n",
      "4           6.190e-01  2.553e-01  (x1 - log10_abs(x2))\n",
      "7           5.908e-01  1.554e-02  ((2.9686167 * x1) + (-3.5632546 * x2))\n",
      "8           5.679e-01  3.962e-02  ((2.3849034 - log_abs(x1)) * (x1 - x2))\n",
      "10          5.659e-01  1.701e-03  (x1 + (-1.07813 * log10_abs(x2 + (-0.09936239 * x3))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.434756 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.076545 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.25267908 + (x4 + (2.1288564 * x1)))\n",
      "9           6.693e-01  6.832e-02  (-0.5448855 + ((-0.5488192 * x3) + (2.3172386 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.990e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 24 / 1200 total iterations (2.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979323 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.143e-01  3.843e-03  (x1 - log10_abs(x2 * 1.2160699))\n",
      "8           5.966e-01  1.461e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "10          5.663e-01  2.607e-02  (x1 - log10_abs((x2 + (x3 * -0.09657265)) * -1.0948982))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.0765564 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.2530826 + (x4 + (2.1288114 * x1)))\n",
      "9           6.986e-01  4.684e-02  (x4 + ((-0.35670036 * x3) + (1.9270647 * x1)))\n",
      "10          6.585e-01  5.921e-02  (x4 + ((3.4497137 * x2) + (x3 * log10_abs(x0))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.770e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 25 / 1200 total iterations (2.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37979323 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.143e-01  3.843e-03  (x1 - log10_abs(x2 * 1.2160699))\n",
      "8           5.966e-01  1.461e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "10          5.663e-01  2.607e-02  (x1 - log10_abs((x2 + (x3 * -0.09657265)) * -1.0948982))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.131e+00  4.509e-01  (2.5918505 * x1)\n",
      "4           1.117e+00  1.246e-02  (sqrt_abs(5.5143814) * x1)\n",
      "5           8.352e-01  2.909e-01  ((x1 * 1.9893233) + x4)\n",
      "7           7.673e-01  4.239e-02  (-0.25282595 + (x4 + (2.128735 * x1)))\n",
      "8           6.761e-01  1.265e-01  (x4 + (x1 * sqrt_abs(4.6921225 / x1)))\n",
      "10          6.077e-01  5.331e-02  (x2 + (x4 + (x1 * log_abs(5.268682 / x1))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.750e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 27 / 1200 total iterations (2.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797861 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41367182 * log_abs(x2)))\n",
      "8           5.966e-01  1.780e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.265e+00  3.950e-01  (x1 + x1)\n",
      "4           1.111e+00  1.295e-01  (x1 * sqrt_abs(6.014003))\n",
      "5           8.822e-01  2.308e-01  ((x1 * 3.2053354) - x0)\n",
      "6           8.366e-01  5.304e-02  (x1 * sqrt_abs(-6.5326552 / x1))\n",
      "7           7.727e-01  7.943e-02  ((-0.6377825 * x0) + (2.913713 * x1))\n",
      "8           6.761e-01  1.336e-01  (x4 + (x1 * sqrt_abs(4.6921225 / x1)))\n",
      "9           6.611e-01  2.232e-02  (-0.3417246 + ((-0.59988934 * x0) + (2.9557881 * x1)))\n",
      "10          6.077e-01  8.430e-02  (x2 + (x4 + (x1 * log_abs(5.268682 / x1))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 2.620e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 28 / 1200 total iterations (2.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797861 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.182e-01  6.523e-04  (x1 + (-0.41367182 * log_abs(x2)))\n",
      "8           5.966e-01  1.780e-02  (x1 + (-0.94355124 * log10_abs(0.06880875 + x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.232e+00  4.080e-01  (x1 / 0.48811185)\n",
      "5           8.337e-01  1.954e-01  ((x1 + x4) + x1)\n",
      "8           8.279e-01  2.349e-03  (x1 - ((x3 - x1) + sqrt_abs(x2)))\n",
      "9           6.693e-01  2.127e-01  (-0.5449041 + ((-0.5488431 * x3) + (2.317193 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           7.848e+00  1.477e-01  (x1 + x0)\n",
      "4           6.749e+00  1.510e-01  (x1 - log_abs(x2))\n",
      "6           5.172e+00  1.330e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  (((x4 + x0) + x1) - log_abs(x2))\n",
      "10          4.191e+00  3.910e-02  ((x1 + (x0 + x4)) - log_abs(x1 - 0.3692989))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 2.770e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 30 / 1200 total iterations (2.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972298 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85042274 / x2))\n",
      "8           6.078e-01  5.104e-03  (x1 + log10_abs(-0.3060487 + (0.8593486 / x2)))\n",
      "9           5.971e-01  1.785e-02  ((x1 - log10_abs(x2 * sqrt_abs(x1))) - 0.18158987)\n",
      "10          5.677e-01  5.047e-02  (x1 + log10_abs((-1.0497826 / x2) + (-0.7018149 * x3)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.232e+00  4.080e-01  (x1 / 0.48811185)\n",
      "5           8.337e-01  1.954e-01  ((x1 + x4) + x1)\n",
      "8           8.279e-01  2.349e-03  (x1 - ((x3 - x1) + sqrt_abs(x2)))\n",
      "9           6.693e-01  2.127e-01  (-0.5449041 + ((-0.5488431 * x3) + (2.317193 * x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "3           7.265e+00  1.273e-01  (x1 + x1)\n",
      "4           6.749e+00  7.369e-02  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71886116 + (2.6453934 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "8           4.560e+00  3.737e-02  (((x0 + x1) + x1) - log_abs(x2))\n",
      "10          4.217e+00  3.903e-02  (-0.9306045 + ((-1.5786276 * log_abs(x2)) + (2.7231658 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.210e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 33 / 1200 total iterations (2.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972295 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85011387 / x2))\n",
      "7           5.908e-01  3.858e-02  ((-3.5634954 * x2) + (2.96877 * x1))\n",
      "9           5.882e-01  2.222e-03  (-0.073791474 + ((3.1524632 * x1) + (-3.8719606 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347527 * x1)\n",
      "5           8.290e-01  1.464e-01  (x4 + (2.07655 * x1))\n",
      "7           7.673e-01  3.867e-02  (-0.2528399 + (x4 + (2.128747 * x1)))\n",
      "9           7.532e-01  9.242e-03  (-0.1331652 + (x2 + (x4 + (1.5579417 * x1))))\n",
      "10          6.607e-01  1.311e-01  (x4 + ((1.8001357 * x1) + log10_abs(0.34272045 + x1)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "3           7.265e+00  1.273e-01  (x1 + x1)\n",
      "4           6.749e+00  7.369e-02  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.71886116 + (2.6453934 * x1))\n",
      "6           4.913e+00  2.411e-01  ((x1 + x1) - log_abs(x2))\n",
      "8           4.560e+00  3.737e-02  (((x0 + x1) + x1) - log_abs(x2))\n",
      "10          4.217e+00  3.903e-02  (-0.9306045 + ((-1.5786276 * log_abs(x2)) + (2.7231658 * x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.070e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 36 / 1200 total iterations (3.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37972295 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(0.85011387 / x2))\n",
      "7           5.908e-01  3.858e-02  ((-3.5634954 * x2) + (2.96877 * x1))\n",
      "9           5.882e-01  2.222e-03  (-0.073791474 + ((3.1524632 * x1) + (-3.8719606 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.793656 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188273 + (2.6452773 * x1))\n",
      "6           5.172e+00  1.898e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  ((x1 + (x0 + x4)) - log_abs(x2))\n",
      "10          4.112e+00  4.857e-02  (((x1 + x1) - log_abs(x1 - 0.2593729)) / 0.6445904)\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.480e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 39 / 1200 total iterations (3.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.3797341 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "6           6.140e-01  4.015e-03  (x1 + log10_abs(-0.8504216 / x2))\n",
      "7           6.119e-01  3.561e-03  (x1 + sqrt_abs(log10_abs(-0.36682373 + x1)))\n",
      "9           5.966e-01  1.267e-02  (x1 + log10_abs(log10_abs(0.15950276 * x3) / x2))\n",
      "10          5.824e-01  2.393e-02  (x1 + log10_abs(-0.90379727 / (x2 + (0.115976155 * x0))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.793656 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188273 + (2.6452773 * x1))\n",
      "6           5.172e+00  1.898e-01  ((x1 + x0) - log_abs(x2))\n",
      "8           4.532e+00  6.606e-02  ((x1 + (x0 + x4)) - log_abs(x2))\n",
      "10          4.112e+00  4.857e-02  (((x1 + x1) - log_abs(x1 - 0.2593729)) / 0.6445904)\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.480e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 42 / 1200 total iterations (3.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.421e-01  4.605e-01  x1\n",
      "3           7.979e-01  8.308e-02  (0.37967104 + x1)\n",
      "4           6.190e-01  2.539e-01  (x1 - log10_abs(x2))\n",
      "8           5.698e-01  2.072e-02  (1.8674098 + (x1 + (-2.314192 * sqrt_abs(x2))))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.787e+00  7.562e-01  x1\n",
      "3           1.111e+00  4.598e-01  (2.4347353 * x1)\n",
      "5           9.994e-01  5.292e-02  ((x1 + x4) + x2)\n",
      "6           8.367e-01  1.777e-01  (sqrt_abs(-6.602573 / x1) * x1)\n",
      "8           7.983e-01  2.350e-02  ((x1 * 2.190498) - (sqrt_abs(x2) + x3))\n",
      "9           6.693e-01  1.763e-01  (-0.5448973 + ((-0.5488515 * x3) + (2.3172061 * x1)))\n",
      "10          6.321e-01  5.710e-02  ((x1 * 2.3593307) - (sqrt_abs(x2) + (x3 * 0.59716284)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           9.371e+00  2.264e-01  x1\n",
      "2           9.097e+00  2.968e-02  exp(x1)\n",
      "3           6.752e+00  2.981e-01  (2.7937005 * x1)\n",
      "4           6.749e+00  4.822e-04  (x1 - log_abs(x2))\n",
      "5           6.253e+00  7.627e-02  (0.7188429 + (2.6452808 * x1))\n",
      "6           4.913e+00  2.411e-01  (x1 + (x1 - log_abs(x2)))\n",
      "8           4.679e+00  2.442e-02  (x1 + (x1 - log_abs(x1 - 0.45799425)))\n",
      "10          3.656e+00  1.234e-01  (x0 + (x1 + (-1.9220711 * log_abs(-0.39283225 + x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Killing process... will return when done.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "g1_equations = pysr(\n",
    "    X=x_g1_pysr, y=y_g1_pysr,\n",
    "    procs=4,\n",
    "    niterations=20,\n",
    "    populations=20,\n",
    "    useFrequency=True,\n",
    "    multithreading=True, \n",
    "    binary_operators=[\"plus\", \"sub\", \"mult\", \"div\"],\n",
    "    unary_operators = ['log10_abs', 'sqrt_abs', 'exp', 'log'], ##still need a general power law\n",
    "    batching=1, \n",
    "    batchSize=256,\n",
    "    maxsize=10, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ef6a182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                                4\n",
       "MSE                                                0.618991\n",
       "score                                              0.253895\n",
       "Equation                               (x1 - log10_abs(x2))\n",
       "sympy_format                      x1 - log(Abs(x2))/log(10)\n",
       "lambda_format    PySRFunction(X=>x1 - log(Abs(x2))/log(10))\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[0].sort_values(by='score', ascending=False).iloc[0]\n",
    "a=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3ce5b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                          3\n",
       "MSE                                          1.143048\n",
       "score                                        0.445626\n",
       "Equation                            (x1 / 0.37977126)\n",
       "sympy_format                      2.63316397349289*x1\n",
       "lambda_format    PySRFunction(X=>2.63316397349289*x1)\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[1].sort_values(by='score', ascending=False).iloc[0]\n",
    "b=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33090e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complexity                                   3\n",
       "MSE                                   6.751929\n",
       "score                                 0.298143\n",
       "Equation                      (2.7937005 * x1)\n",
       "sympy_format                      2.7937005*x1\n",
       "lambda_format    PySRFunction(X=>2.7937005*x1)\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq = g1_equations[2].sort_values(by='score', ascending=False).iloc[0]\n",
    "c=eq['lambda_format'](x_g1[0])\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5414aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_an_pysr = np.vstack([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838585ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on julia -O3 --threads 4 /tmp/tmpgyms7yzv/runfile.jl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Activating environment at `~/.conda/envs/juptorch_julia/lib/python3.9/site-packages/Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n",
      "\n",
      "Cycles per second: 5.180e+03\n",
      "Head worker occupation: 8.3%\n",
      "Progress: 2 / 1200 total iterations (0.167%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2790511\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.2852532 + (-0.26651594 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.950e+03\n",
      "Head worker occupation: 5.1%\n",
      "Progress: 3 / 1200 total iterations (0.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.440e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 4 / 1200 total iterations (0.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.710e+03\n",
      "Head worker occupation: 1.1%\n",
      "Progress: 5 / 1200 total iterations (0.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           8.282e-01  6.981e-02  sqrt_abs(1.3321475 - x0)\n",
      "5           5.994e-01  3.233e-01  (1.285261 + (-0.26652515 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.430e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 6 / 1200 total iterations (0.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.285257 + (-0.2665256 * x1))\n",
      "6           5.982e-01  2.089e-03  sqrt_abs(1.9554164 + (-0.6193561 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.740e+03\n",
      "Head worker occupation: 0.9%\n",
      "Progress: 8 / 1200 total iterations (0.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.750e+03\n",
      "Head worker occupation: 0.8%\n",
      "Progress: 9 / 1200 total iterations (0.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 3.420e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 10 / 1200 total iterations (0.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.350e+03\n",
      "Head worker occupation: 0.7%\n",
      "Progress: 13 / 1200 total iterations (1.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.095e-03  sqrt_abs(-1.9597083 + (0.6207334 * x1))\n",
      "8           5.827e-01  1.316e-02  sqrt_abs(log_abs(-0.73548853 + (-5.0798693 / exp(x1))))\n",
      "10          5.551e-01  2.423e-02  sqrt_abs(log_abs(-0.76794374 + ((-4.9026785 + x2) / exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.450e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 15 / 1200 total iterations (1.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852541 + (-0.26650703 * x1))\n",
      "6           5.982e-01  2.093e-03  sqrt_abs(1.9594429 + (-0.6206558 * x1))\n",
      "8           5.891e-01  7.699e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.648e-01  2.098e-02  sqrt_abs(0.11480782 + exp(1.308776 + (-0.45345652 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.080e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 16 / 1200 total iterations (1.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2788731\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.648e-01  2.098e-02  sqrt_abs(0.11480782 + exp(1.308776 + (-0.45345652 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.810e+03\n",
      "Head worker occupation: 0.6%\n",
      "Progress: 19 / 1200 total iterations (1.583%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2786434\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171164 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.110e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 21 / 1200 total iterations (1.750%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 5.100e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 22 / 1200 total iterations (1.833%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.060e+03\n",
      "Head worker occupation: 0.5%\n",
      "Progress: 23 / 1200 total iterations (1.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25171337 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852596 + (-0.26653382 * x1))\n",
      "6           5.982e-01  2.096e-03  sqrt_abs(1.959238 + (-0.6205837 * x1))\n",
      "8           5.891e-01  7.697e-03  sqrt_abs(exp(1.3203932 + (-0.38085437 * exp(x1))))\n",
      "10          5.699e-01  1.651e-02  sqrt_abs(sqrt_abs(exp(log10_abs(exp(x2) + -1.2699978) - x1)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.730e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 25 / 1200 total iterations (2.083%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25174072 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852515 + (-0.2665252 * x1))\n",
      "6           5.982e-01  2.083e-03  sqrt_abs(1.9546335 + (-0.6191466 * x1))\n",
      "7           5.891e-01  1.541e-02  exp(0.6601062 + (-0.19049618 * exp(x1)))\n",
      "9           5.862e-01  2.450e-03  exp((x1 + (sqrt_abs(x1) - 1.815573)) * -0.24319673)\n",
      "10          5.570e-01  5.109e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.650e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 28 / 1200 total iterations (2.333%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.25174072 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852579 + (-0.26652578 * x1))\n",
      "6           5.982e-01  2.072e-03  sqrt_abs(1.9627051 + (-0.62186176 * x1))\n",
      "7           5.873e-01  1.847e-02  (sqrt_abs(sqrt_abs(9.484525) - x1) + -0.39439014)\n",
      "8           5.845e-01  4.689e-03  (-0.30447757 + sqrt_abs(2.8036215 + (-0.8870912 * x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 5.130e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 30 / 1200 total iterations (2.500%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2789322\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852509 + (-0.26652473 * x1))\n",
      "6           5.982e-01  2.082e-03  sqrt_abs(1.9564418 + (-0.61975557 * x1))\n",
      "7           5.891e-01  1.541e-02  exp(0.6601307 + (-0.19048771 * exp(x1)))\n",
      "8           5.845e-01  7.735e-03  (-0.30447757 + sqrt_abs(2.8036215 + (-0.8870912 * x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.150e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 32 / 1200 total iterations (2.667%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852594 + (-0.26652542 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042943 + ((0.07095845 * x2) + (-0.33296615 * x1)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycles per second: 4.950e+03\n",
      "Head worker occupation: 0.4%\n",
      "Progress: 35 / 1200 total iterations (2.917%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852598 + (-0.26652578 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.910e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 36 / 1200 total iterations (3.000%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852598 + (-0.26652578 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 4.030e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 39 / 1200 total iterations (3.250%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  1.192e-07  1.278901\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517181 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852643 + (-0.26654008 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "8           5.845e-01  1.417e-03  (-0.30342862 + (0.94143367 * sqrt_abs(-3.159909 + x1)))\n",
      "9           5.665e-01  3.136e-02  (1.2042917 + ((-0.3329634 * x1) + (0.07096216 * x2)))\n",
      "10          5.570e-01  1.690e-02  ((-0.34644172 * x1) + (1.144835 * exp(0.072146975 * x2)))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n",
      "\n",
      "Cycles per second: 3.870e+03\n",
      "Head worker occupation: 0.3%\n",
      "Progress: 41 / 1200 total iterations (3.417%)\n",
      "==============================\n",
      "Best equations for output 1\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.406e-02  -0.000e+00  -0.3479579\n",
      "5           1.762e-02  7.788e-02  (-0.3471601 + (-0.032939747 * x1))\n",
      "8           1.757e-02  9.525e-04  (-0.7191795 + exp(-1.0134043 + (-0.092179745 * x1)))\n",
      "9           1.641e-02  6.816e-02  (-0.362665 + ((-0.045649357 * x1) + (0.013580261 * x2)))\n",
      "\n",
      "==============================\n",
      "Best equations for output 2\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           2.068e-02  -0.000e+00  -0.23073237\n",
      "5           1.325e-02  1.114e-01  (-0.23157844 + (0.035398062 * x1))\n",
      "\n",
      "==============================\n",
      "Best equations for output 3\n",
      "Hall of Fame:\n",
      "-----------------------------------------\n",
      "Complexity  Loss       Score     Equation\n",
      "1           1.021e+00  -0.000e+00  1.2790481\n",
      "4           6.409e-01  1.553e-01  exp(-0.2517328 * x1)\n",
      "5           5.994e-01  6.693e-02  (1.2852972 + (-0.26651946 * x1))\n",
      "6           5.862e-01  2.239e-02  (-0.4006784 + sqrt_abs(-3.1526465 + x1))\n",
      "7           5.752e-01  1.888e-02  log10_abs(exp(1.9263862 - x1) + x2)\n",
      "8           5.707e-01  7.786e-03  log10_abs(exp(exp(0.74600375) - x1) + x2)\n",
      "9           5.671e-01  6.467e-03  log10_abs(x2 + exp(2.390812 + (-0.8634285 * x1)))\n",
      "10          5.169e-01  9.272e-02  log10_abs(x2 + exp(4.511248 + (-1.0051906 * exp(x1))))\n",
      "\n",
      "==============================\n",
      "Press 'q' and then <enter> to stop execution early.\n"
     ]
    }
   ],
   "source": [
    "g2_equations = pysr(\n",
    "    X=y_g1_pysr, y=y_g2_pysr,\n",
    "    procs=4,\n",
    "    niterations=20,\n",
    "    populations=20,\n",
    "    useFrequency=True,\n",
    "    multithreading=True, \n",
    "    binary_operators=[\"plus\", \"sub\", \"mult\", \"div\", 'pow'],\n",
    "    unary_operators = ['log10_abs', 'sqrt_abs', 'exp', 'log'], ##still need a general power law\n",
    "    batching=1, \n",
    "    batchSize=256,\n",
    "    maxsize=10, update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aca42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
