{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a556f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, pickle\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "path='../../../../tigress/mcranmer/merger_trees/isotrees/'\n",
    "def convert(d,p):\n",
    "    dfin=[]\n",
    "    if len(p)!=len(np.unique(p)):\n",
    "        print('Wrong order of prog/desc')\n",
    "    else:\n",
    "        no=d[0]\n",
    "        for desc in d:\n",
    "            if desc==no:\n",
    "                dfin.append(0)\n",
    "            else:\n",
    "                dfin.append(p.index(desc)+1)\n",
    "    return dfin, np.arange(1, 1+len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08503d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=np.array([0,2,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,35]+list(range(37,60)))\n",
    "is_cat=[0,1,0,1,1,1,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,\\\n",
    "        0,0,0,0,0,0,0,0,0,0,0]\n",
    "cols=np.array([0,2,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,35]+list(range(37,60)))\n",
    "# cols=np.array([0,2,4,5,6,7,8,10])\n",
    "case='222_all'\n",
    "is_cat=np.array([bool(i) for i in is_cat])\n",
    "i0,i1=0,2\n",
    "j0,j1=0,2\n",
    "k0,k1=0,2\n",
    "scaler = pickle.load(open('transformer0.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading isotree 0_0_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cj1223/.conda/envs/juptorch/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isotree 0_0_0 loaded, restructuring\n",
      "Splitting to tree\n",
      "Split done\n",
      "Loading targets\n",
      "Making merger tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 769/769 [00:42<00:00, 18.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 769/769 [00:00<00:00, 2763.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with tree. \n",
      " Time elapsed 172.76603198051453 s\n",
      "Loading isotree 0_0_1\n",
      "isotree 0_0_1 loaded, restructuring\n",
      "Splitting to tree\n",
      "Split done\n",
      "Loading targets\n",
      "Making merger tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1338/1338 [02:17<00:00,  9.76it/s]\n",
      "100%|████████████████████████████████████████████████████████| 1338/1338 [00:00<00:00, 10243.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with tree. \n",
      " Time elapsed 390.32353496551514 s\n",
      "Loading isotree 0_0_2\n",
      "isotree 0_0_2 loaded, restructuring\n",
      "Splitting to tree\n",
      "Split done\n",
      "Loading targets\n",
      "Making merger tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1476/1476 [14:40<00:00,  1.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 1476/1476 [00:00<00:00, 5600.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with tree. \n",
      " Time elapsed 1209.3880019187927 s\n",
      "Loading isotree 0_1_0\n",
      "isotree 0_1_0 loaded, restructuring\n",
      "Splitting to tree\n",
      "Split done\n",
      "Loading targets\n",
      "Making merger tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1128/1128 [07:05<00:00,  2.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 1128/1128 [00:00<00:00, 8979.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with tree. \n",
      " Time elapsed 664.5416121482849 s\n",
      "Loading isotree 0_1_1\n",
      "isotree 0_1_1 loaded, restructuring\n",
      "Splitting to tree\n",
      "Split done\n",
      "Loading targets\n",
      "Making merger tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████▍            | 1526/1937 [13:54<00:52,  7.84it/s]"
     ]
    }
   ],
   "source": [
    "dat=[]\n",
    "for i in range(i0,i1+1):\n",
    "    for j in range(j0,j1+1):\n",
    "        for k in range(k0,k1+1):\n",
    "            print(f'Loading isotree {i}_{j}_{k}')\n",
    "            start=time.time()\n",
    "            pd1=pd.read_table(path+f'isotree_{i}_{j}_{k}.dat', skiprows=0, delimiter='\\s+') # consider enforcing dtypes upon import\n",
    "            print(f'isotree {i}_{j}_{k} loaded, restructuring')\n",
    "            raw=pd1.drop(axis=0, index=np.arange(50)).reset_index()\n",
    "            trees=raw[raw.isna()['A[z]']] \n",
    "            halos=raw[~raw.isna()['A[z]']] \n",
    "            del raw\n",
    "            del pd1\n",
    "            f,it=\"float64\", \"int64\"\n",
    "            cs=[f,it,f,it,it,it,it,it,it,f,f,f,f,f,it,f,f,f,f,f,f,f,f,f,f,f]\n",
    "            dicts = {}\n",
    "            keys = halos.columns[1:26]\n",
    "            castto = cs\n",
    "            for d, key in enumerate(keys):\n",
    "                    dicts[key] = castto[d]\n",
    "            halos=halos.astype(dicts)\n",
    "            \n",
    "            hard=[0,2,15]\n",
    "            def logit(x):\n",
    "                return np.log10((x+0.001)/(1.01-x))\n",
    "            ##logit transform the hards\n",
    "            for h in hard:\n",
    "                halos[halos.columns[h+1]]=logit(halos[halos.columns[h+1]])\n",
    "            log=[10,38, 39, 40, 41, 42]\n",
    "\n",
    "            def logt(x):\n",
    "                return np.log10(x+1)\n",
    "            for l in log:\n",
    "                halos[halos.columns[l+1]]=logt(halos[halos.columns[l+1]])\n",
    "            tcols=np.array(cols[~is_cat[cols]])+1\n",
    "#             halos[halos.columns[tcols]]=scaler.transform(halos[halos.columns[tcols]])\n",
    "            \n",
    "            print(f'Splitting to tree')\n",
    "            spli=np.split(np.array(halos)[:,1:], np.array(trees.iloc[1:].index)-np.arange(1,len(trees.index)))\n",
    "            splits=[]\n",
    "            for s in spli:\n",
    "                if s[0,10]>10:\n",
    "                    splits.append(s)\n",
    "            splits=np.array(splits, dtype=object)\n",
    "            split=[]\n",
    "            for tree in splits:\n",
    "                s=tree[np.logical_or(tree[:,3] == -1,tree[:,4]!=1)]\n",
    "                split.append(s)\n",
    "            split=np.array(split, dtype=object)\n",
    "            print('Split done')\n",
    "            print('Loading targets')\n",
    "            samp='~/../../../tigress/mcranmer/merger_trees/samout/'\n",
    "            ex=f'{i}_{j}_{k}/'\n",
    "            ex+='galprop_0-99.dat'\n",
    "            pdc=pd.read_table(samp+ex, skiprows=0, delimiter=',', nrows=41, header=None)\n",
    "            newcols=pdc.iloc[:,0]\n",
    "            pds=pd.read_table(samp+ex, skiprows=41, delimiter='\\s+', header=None)\n",
    "            pds.columns=np.array(newcols)\n",
    "            pd0=pds[pds[pds.columns[3]]==0.00] # subhaloes\n",
    "            pdcen=pd0[(pd0[pds.columns[1]]==pd0[pds.columns[2]])] ##central haloes\n",
    "            \n",
    "            rhalid=np.array(pdcen[pds.columns[2]])\n",
    "            del pd0\n",
    "            del pds\n",
    "            halwgal=[]\n",
    "            ids=[]\n",
    "            out=[]\n",
    "            for idx, tree in enumerate(split):\n",
    "                if tree[0,1] in rhalid:\n",
    "                    halwgal.append(tree)\n",
    "                    ids.append(idx)\n",
    "                    index=np.where(rhalid==tree[0,1])\n",
    "                    out.append(np.array(pdcen.iloc[index])[0][8]) ## target variable\n",
    "            del pdcen\n",
    "            stop=time.time()\n",
    "            hraw=np.array(splits[ids], dtype=object)\n",
    "            hals=[]\n",
    "            pr,de=[],[]\n",
    "            print('Making merger tree')\n",
    "            for n in tqdm(range(len(halwgal))):\n",
    "                h=halwgal[n]\n",
    "                roots=h[h[:,4]==0]\n",
    "            #     mergers=h[np.logical_and(h[:,4]>1,h[:,3]!=-1)] #remove self-loop, is broken since some roots go directly to final\n",
    "                mergers=h[h[:,4]>1]\n",
    "                final=h[h[:,3]==-1]\n",
    "                pro, des=[],[]\n",
    "                for r in roots:\n",
    "                    descid=hraw[n][:,3][np.where(r[1]==hraw[n][:,1])]\n",
    "                    while descid not in mergers[:,1]:\n",
    "                        descid=hraw[n][:,3][np.where(descid==hraw[n][:,1])] #consider adding the number of steps it went through\n",
    "                    pro.append(r[1])\n",
    "                    des.append(descid[0])\n",
    "                m=mergers[mergers[:, 0].argsort()] #sort by redshift, starting at early times\n",
    "                mdes,mpro=list(m[:,1][1:]), list(m[:,1])\n",
    "                des+=mdes\n",
    "                pro+=mpro\n",
    "                des.append(final[:,1][0])\n",
    "                des,pro=convert(des[::-1],pro[::-1])\n",
    "                hal2=np.vstack([final,np.flip(m,axis=0).copy(),np.flip(roots,axis=0).copy()])\n",
    "                hal2=hal2[:,cols] \n",
    "                hals.append(hal2)\n",
    "                pr.append([int(p) for p in pro])\n",
    "                de.append([int(d) for d in des])\n",
    "            hals=np.array(hals,dtype=object)\n",
    "            out=np.log(out)/5 #homemade scaling\n",
    "            for n in tqdm(range(len(out))):\n",
    "                edge_index = torch.tensor([pr[n],de[n]], dtype=torch.long)\n",
    "                x = torch.tensor(hals[n], dtype=torch.float)\n",
    "\n",
    "                y=torch.tensor(out[n], dtype=torch.float)\n",
    "                graph=Data(x=x, edge_index=edge_index, y=y)\n",
    "                dat.append(graph)\n",
    "            stop=time.time()\n",
    "            print(f'Done with tree. \\n Time elapsed {stop-start} s')\n",
    "print(\"Saving dataset\")\n",
    "if not osp.exists(f'../../../../scratch/gpfs/cj1223/GraphStorage/{case}'):\n",
    "    os.mkdir(f'../../../../scratch/gpfs/cj1223/GraphStorage/{case}')\n",
    "                  \n",
    "with open(f'../../../../scratch/gpfs/cj1223/GraphStorage/{case}/data.pkl', 'wb') as handle:\n",
    "    pickle.dump(dat, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loading isotree {i}_{j}_{k}')\n",
    "start=time.time()\n",
    "pd1=pd.read_table(path+f'isotree_{i}_{j}_{k}.dat', skiprows=0, delimiter='\\s+') # consider enforcing dtypes upon import\n",
    "print(f'isotree {i}_{j}_{k} loaded, restructuring')\n",
    "raw=pd1.drop(axis=0, index=np.arange(50)).reset_index()\n",
    "trees=raw[raw.isna()['A[z]']] \n",
    "halos=raw[~raw.isna()['A[z]']] \n",
    "f,it=\"float64\", \"int64\"\n",
    "cs=[f,it,f,it,it,it,it,it,it,f,f,f,f,f,it,f,f,f,f,f,f,f,f,f,f,f]\n",
    "dicts = {}\n",
    "keys = halos.columns[1:26]\n",
    "castto = cs\n",
    "for d, key in enumerate(keys):\n",
    "        dicts[key] = castto[d]\n",
    "halos=halos.astype(dicts)\n",
    "\n",
    "hard=[0,2,15]\n",
    "def logit(x):\n",
    "    return np.log10((x+0.001)/(1.01-x))\n",
    "##logit transform the hards\n",
    "for h in hard:\n",
    "    halos[halos.columns[h+1]]=logit(halos[halos.columns[h+1]])\n",
    "log=[10,38, 39, 40, 41, 42]\n",
    "\n",
    "def logt(x):\n",
    "    return np.log10(x+1)\n",
    "for l in log:\n",
    "    halos[halos.columns[l+1]]=logt(halos[halos.columns[l+1]])\n",
    "tcols=np.array(cols[~is_cat[cols]])+1\n",
    "halos[halos.columns[tcols]]=scaler.transform(halos[halos.columns[tcols]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Restructured, splitting to tree')\n",
    "spli=np.split(np.array(halos)[:,1:], np.array(trees.iloc[1:].index)-np.arange(1,len(trees.index)))\n",
    "splits=[]\n",
    "for s in spli:\n",
    "    if s[0,10]>1:\n",
    "        splits.append(s)\n",
    "splits=np.array(splits, dtype=object)\n",
    "split=[]\n",
    "for tree in splits:\n",
    "    s=tree[np.logical_or(tree[:,3] == -1,tree[:,4]!=1)]\n",
    "    split.append(s)\n",
    "split=np.array(split, dtype=object)\n",
    "print('Split done')\n",
    "print(len(split))\n",
    "print('Loading targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d41cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp='~/../../../tigress/mcranmer/merger_trees/samout/'\n",
    "ex=f'{0}_{j}_{k}/'\n",
    "ex+='galprop_0-99.dat'\n",
    "pdc=pd.read_table(samp+ex, skiprows=0, delimiter=',', nrows=41, header=None)\n",
    "newcols=pdc.iloc[:,0]\n",
    "pds=pd.read_table(samp+ex, skiprows=41, delimiter='\\s+', header=None)\n",
    "pds.columns=np.array(newcols)\n",
    "pd0=pds[pds[pds.columns[3]]==0.00] # subhaloes\n",
    "pdcen=pd0[(pd0[pds.columns[1]]==pd0[pds.columns[2]])] ##central haloes\n",
    "\n",
    "rhalid=np.array(pdcen[pds.columns[2]])\n",
    "halwgal=[]\n",
    "ids=[]\n",
    "out=[]\n",
    "for idx, tree in enumerate(split):\n",
    "    if tree[0,1] in rhalid:\n",
    "        halwgal.append(tree)\n",
    "        ids.append(idx)\n",
    "        index=np.where(rhalid==tree[0,1])\n",
    "        out.append(np.array(pdcen.iloc[index])[0][8]) ## target variable\n",
    "stop=time.time()\n",
    "hraw=np.array(splits[ids], dtype=object)\n",
    "len(hraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hals=[]\n",
    "pr,de=[],[]\n",
    "print('Making merger tree')\n",
    "for i in tqdm(range(len(halwgal))):\n",
    "    h=halwgal[i]\n",
    "    roots=h[h[:,4]==0]\n",
    "#     mergers=h[np.logical_and(h[:,4]>1,h[:,3]!=-1)] #remove self-loop, is broken since some roots go directly to final\n",
    "    mergers=h[h[:,4]>1]\n",
    "    final=h[h[:,3]==-1]\n",
    "    pro, des=[],[]\n",
    "    for r in roots:\n",
    "        descid=hraw[i][:,3][np.where(r[1]==hraw[i][:,1])]\n",
    "        while descid not in mergers[:,1]:\n",
    "            descid=hraw[i][:,3][np.where(descid==hraw[i][:,1])] #consider adding the number of steps it went through\n",
    "        pro.append(r[1])\n",
    "        des.append(descid[0])\n",
    "    m=mergers[mergers[:, 0].argsort()] #sort by redshift, starting at early times\n",
    "    mdes,mpro=list(m[:,1][1:]), list(m[:,1])\n",
    "    des+=mdes\n",
    "    pro+=mpro\n",
    "    des.append(final[:,1][0])\n",
    "    des,pro=convert(des[::-1],pro[::-1])\n",
    "    hal2=np.vstack([final,np.flip(m,axis=0).copy(),np.flip(roots,axis=0).copy()])\n",
    "    hal2=hal2[:,cols] \n",
    "    hals.append(hal2)\n",
    "    pr.append([int(p) for p in pro])\n",
    "    de.append([int(d) for d in des])\n",
    "hals=np.array(hals,dtype=object)\n",
    "for n in tqdm(range(len(out))):\n",
    "    edge_index = torch.tensor([pr[n],de[n]], dtype=torch.long)\n",
    "    x = torch.tensor(hals[n], dtype=torch.float)\n",
    "\n",
    "    y=torch.tensor(out[n], dtype=torch.float)\n",
    "    graph=Data(x=x, edge_index=edge_index, y=y)\n",
    "    dat.append(graph)\n",
    "stop=time.time()\n",
    "print(f'Done with tree. \\n Time elapsed {stop-start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f6960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
